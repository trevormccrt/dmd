{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "First, let's embed a ring in 3D."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "from scipy import integrate\n",
    "import torch\n",
    "\n",
    "sys.path.append(os.path.join(os.getenv(\"HOME\"), \"RNN_Manifold/\"))\n",
    "import decode_1d, generate_1d, geometry_util"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trevor/brainvenv/lib/python3.8/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (20000x3 and 2x750)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m encoder, decoder \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_1d\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_training_iterations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3000\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m angles \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marange(start\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, stop\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39mpi, step\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n",
      "File \u001B[0;32m~/RNN_Manifold/generate_1d.py:30\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(n_circular_dimensions, n_linear_dimensions, embedding_dimension, device, encoder_hidden_dim, encoder_n_hidden, decoder_hidden_dim, decoder_n_hidden, integration_resamples, n_points_compare, batch_size, n_training_iterations, loss_stop_thresh)\u001B[0m\n\u001B[1;32m     27\u001B[0m decoding_cost \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmean(torch\u001B[38;5;241m.\u001B[39msquare(re_encoded_phases \u001B[38;5;241m-\u001B[39m sample_phases))\n\u001B[1;32m     29\u001B[0m rolled_sample_phases \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mroll(sample_phases, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m---> 30\u001B[0m angular_distances, model_distances \u001B[38;5;241m=\u001B[39m \u001B[43mencoder_net\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mminimum_straight_line_distance\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample_phases\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrolled_sample_phases\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mintegration_resamples\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m normed_angular_distance \u001B[38;5;241m=\u001B[39m angular_distances \u001B[38;5;241m/\u001B[39m torch\u001B[38;5;241m.\u001B[39mmean(angular_distances)\n\u001B[1;32m     32\u001B[0m normed_model_distance \u001B[38;5;241m=\u001B[39m model_distances \u001B[38;5;241m/\u001B[39m torch\u001B[38;5;241m.\u001B[39mmean(model_distances)\n",
      "File \u001B[0;32m~/RNN_Manifold/encoder_decoder_core.py:59\u001B[0m, in \u001B[0;36mEncoder1D.minimum_straight_line_distance\u001B[0;34m(self, start_phases, end_phases, n_points_integrate)\u001B[0m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mminimum_straight_line_distance\u001B[39m(\u001B[38;5;28mself\u001B[39m, start_phases, end_phases, n_points_integrate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m):\n\u001B[1;32m     57\u001B[0m     angular_distances, start_remap, end_remap \u001B[38;5;241m=\u001B[39m geometry_util\u001B[38;5;241m.\u001B[39mminimum_periodic_distance(\n\u001B[1;32m     58\u001B[0m         start_phases, end_phases)\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m angular_distances, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_length\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstart_remap\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mend_remap\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_points_integrate\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/RNN_Manifold/encoder_decoder_core.py:52\u001B[0m, in \u001B[0;36mEncoder1D.model_length\u001B[0;34m(self, phases_start, phases_end, n_points_integrate)\u001B[0m\n\u001B[1;32m     50\u001B[0m resampled_angles \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmoveaxis(geometry_util\u001B[38;5;241m.\u001B[39mtorch_linspace(phases_start, phases_end, n_points_integrate), \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m     51\u001B[0m resampled_points \u001B[38;5;241m=\u001B[39m geometry_util\u001B[38;5;241m.\u001B[39mtorch_angles_to_ring(resampled_angles)\n\u001B[0;32m---> 52\u001B[0m encoded_points \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresampled_points\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     53\u001B[0m distance \u001B[38;5;241m=\u001B[39m geometry_util\u001B[38;5;241m.\u001B[39mintegrated_point_metric(encoded_points)\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m angular_length, distance\n",
      "File \u001B[0;32m~/RNN_Manifold/encoder_decoder_core.py:46\u001B[0m, in \u001B[0;36mEncoder1D.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     44\u001B[0m flat_circular_points \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mreshape(circular_points, (\u001B[38;5;241m*\u001B[39mcircular_phases\u001B[38;5;241m.\u001B[39msize()[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m], \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m     45\u001B[0m linear_phases \u001B[38;5;241m=\u001B[39m x[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_circular_stop_idx:]\n\u001B[0;32m---> 46\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mflat_circular_points\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlinear_phases\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/brainvenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/brainvenv/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    203\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 204\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/brainvenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/brainvenv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (20000x3 and 2x750)"
     ]
    }
   ],
   "source": [
    "encoder, decoder = generate_1d.train(1, 0, 3, device, n_training_iterations=3000)\n",
    "\n",
    "angles = np.arange(start=0, stop=2 * np.pi, step=0.01)\n",
    "with torch.no_grad():\n",
    "    points = geometry_util.torch_angles_to_ring(torch.tensor(angles, dtype=torch.get_default_dtype()).to(device))\n",
    "    points = torch.unsqueeze(points, -2)\n",
    "    test_embedding = encoder(points)\n",
    "test_embedding = test_embedding.cpu().numpy()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The shape it generates should be pretty much random, as there is nothing in the loss function we use that encourages a specific shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "proj_fig = plt.figure()\n",
    "proj_axs = proj_fig.add_subplot(projection=\"3d\")\n",
    "proj_axs.scatter(test_embedding[:, 0], test_embedding[:, 1], test_embedding[:, 2], cmap=\"hsv\", c=angles)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's generate a higher dimensional ring"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder, decoder = generate_1d.train(1, 0, 24, device, n_training_iterations=3000)\n",
    "\n",
    "angles = np.arange(start=0, stop=2 * np.pi, step=0.01)\n",
    "with torch.no_grad():\n",
    "    points = geometry_util.torch_angles_to_ring(torch.tensor(angles, dtype=torch.get_default_dtype()).to(device))\n",
    "    points = torch.unsqueeze(points, -2)\n",
    "    high_d_generated_ring_data = encoder(points)\n",
    "high_d_generated_ring_data = high_d_generated_ring_data.cpu().numpy()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And then decode it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "high_d_generated_ring_data = high_d_generated_ring_data/np.mean(np.abs(high_d_generated_ring_data))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder, decoder = decode_1d.train(data=high_d_generated_ring_data, n_circular_dimensions=1, n_linear_dimensions=0, device=device,\n",
    "                                                   n_training_iterations=3000, decoder_weight=10, order_red_weight=0.1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    decoded_points, decoded_angles = decoder(torch.tensor(high_d_generated_ring_data, dtype=torch.get_default_dtype()).to(device))\n",
    "\n",
    "predicted_phases = torch.squeeze(decoded_angles).cpu().numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def reference_phases(phases):\n",
    "    phases_refd = phases - phases[0]\n",
    "    phases_refd = np.arctan2(np.sin(phases_refd), np.cos(phases_refd))\n",
    "    return phases_refd * np.sign(phases_refd[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compare_to_ground_truth(predicted_phases, ground_truth_phases, plot_ax):\n",
    "    refd_test_phases = reference_phases(predicted_phases)\n",
    "    refd_true_phases = reference_phases(ground_truth_phases)\n",
    "    line = np.arange(start=-np.pi, stop=np.pi, step=0.01)\n",
    "    plot_ax.scatter(refd_true_phases, refd_test_phases)\n",
    "    plot_ax.plot(line, line, color=\"black\", linestyle=\"--\", label=\"y=x\")\n",
    "    plot_ax.set_xlabel(\"True Phase\")\n",
    "    plot_ax.set_ylabel(\"Found Phase\")\n",
    "    return refd_test_phases, refd_true_phases\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "refd_predicted_phases, refd_true_phases = compare_to_ground_truth(predicted_phases, angles, ax)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's do a harder problem. Let's decode noisy data generated by a dynamic system. First, the dynamics. We will use a typical ring attractor model,"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def conv_circ(signal, ker):\n",
    "    return np.fft.ifft(np.einsum(\"ij, j -> ij\", np.fft.fft(signal, axis=1), np.fft.fft(ker)), axis=1)\n",
    "\n",
    "\n",
    "def cosine_kernel(w_0, w_1, N):\n",
    "    step = 2/(N)\n",
    "    grid = np.arange(start=0, stop=2, step=step) * np.pi\n",
    "    weights = -w_0 + w_1 * np.cos(grid)\n",
    "    return weights\n",
    "\n",
    "\n",
    "def ring_attractor_dynamics(state, kernel, bias_vec, nonlin_fn):\n",
    "    if len(np.shape(state)) == 1:\n",
    "        state = np.expand_dims(state, -1)\n",
    "    state = np.transpose(state)\n",
    "    return np.transpose(-state + nonlin_fn(conv_circ(state, kernel) + bias_vec))\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return np.exp(x)/(np.exp(x) + 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate some samples of equalibrium states. We will generate around 50, to make things interesting."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N = 2 ** 7\n",
    "n_samples = 50\n",
    "\n",
    "init_conds = np.random.uniform(-1, 1, (n_samples, N)).astype(np.complex)\n",
    "\n",
    "w_0 = 1\n",
    "w_1 = 1\n",
    "kernel = cosine_kernel(w_0, w_1, N)\n",
    "\n",
    "\n",
    "def run_equilibriation(init_conds):\n",
    "    soln = integrate.solve_ivp(lambda _, y: ring_attractor_dynamics(y, kernel, np.zeros(N), sigmoid),\n",
    "                               [0, 20], init_conds, vectorized=True)\n",
    "    return soln.y[:, -1]\n",
    "\n",
    "\n",
    "p = mp.Pool()\n",
    "solns = np.array(p.map(run_equilibriation, init_conds))\n",
    "p.close()\n",
    "p.join()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add some noise"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ring_attractor_data = np.real(solns/np.mean(np.abs(solns)))\n",
    "noisy_ring_attractor_data = ring_attractor_data + np.random.normal(0, np.max(ring_attractor_data)/15, np.shape(ring_attractor_data))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note down the ground truth phases"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true_ring_att_phases = (np.argmax(ring_attractor_data, axis=1)/N) * 2 * np.pi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(noisy_ring_attractor_data, aspect=\"auto\")\n",
    "ax.set_title(\"Raw activation data\")\n",
    "ax.set_xlabel(\"Neuron Index\")\n",
    "ax.set_ylabel(\"Datapoint\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now decode"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder, decoder = decode_1d.train(data=noisy_ring_attractor_data, n_circular_dimensions=1, n_linear_dimensions=0, device=device,\n",
    "                                                   n_training_iterations=3000, decoder_weight=10, order_red_weight=0.1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    decoded_points, decoded_angles = decoder(torch.tensor(noisy_ring_attractor_data, dtype=torch.get_default_dtype()).to(device))\n",
    "\n",
    "ring_att_predicted_phases = torch.squeeze(decoded_angles).cpu().numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "refd_ring_att_predicted_phases, refd_ring_att_true_phases = compare_to_ground_truth(ring_att_predicted_phases, true_ring_att_phases, ax)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
