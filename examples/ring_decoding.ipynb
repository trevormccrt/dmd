{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "First, let's embed a ring in 3D."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "from scipy import integrate\n",
    "import torch\n",
    "\n",
    "sys.path.append(os.path.join(os.getenv(\"HOME\"), \"RNN_Manifold/\"))\n",
    "import s1_direct_product_decoder, s1_direct_product_generator, geometry_util"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trevor/brainvenv/lib/python3.8/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0, decoding loss: 1.061689019203186, distance cost: 0.01981627382338047\n",
      "iteration: 3, decoding loss: 0.6815962195396423, distance cost: 0.009346794337034225\n",
      "iteration: 4, decoding loss: 0.34227967262268066, distance cost: 0.03230316936969757\n",
      "iteration: 5, decoding loss: 0.19943171739578247, distance cost: 0.06746604293584824\n",
      "iteration: 13, decoding loss: 0.25694727897644043, distance cost: 0.007828565314412117\n",
      "iteration: 14, decoding loss: 0.1944466382265091, distance cost: 0.007239856291562319\n",
      "iteration: 15, decoding loss: 0.13218756020069122, distance cost: 0.009230935014784336\n",
      "iteration: 16, decoding loss: 0.08851396292448044, distance cost: 0.011823172681033611\n",
      "iteration: 17, decoding loss: 0.060444895178079605, distance cost: 0.014801518060266972\n",
      "iteration: 18, decoding loss: 0.047143951058387756, distance cost: 0.01845703087747097\n",
      "iteration: 165, decoding loss: 0.04258669540286064, distance cost: 0.01971469260752201\n",
      "iteration: 166, decoding loss: 0.0382109135389328, distance cost: 0.01904190517961979\n",
      "iteration: 168, decoding loss: 0.03417599946260452, distance cost: 0.01938345842063427\n",
      "iteration: 169, decoding loss: 0.03555784001946449, distance cost: 0.017623720690608025\n",
      "iteration: 170, decoding loss: 0.035005129873752594, distance cost: 0.014823253266513348\n",
      "iteration: 171, decoding loss: 0.03195711597800255, distance cost: 0.01412543561309576\n",
      "iteration: 172, decoding loss: 0.03027478978037834, distance cost: 0.014131350442767143\n",
      "iteration: 174, decoding loss: 0.03145347908139229, distance cost: 0.012246392667293549\n",
      "iteration: 175, decoding loss: 0.030713221058249474, distance cost: 0.011335487477481365\n",
      "iteration: 176, decoding loss: 0.030851054936647415, distance cost: 0.010782183147966862\n",
      "iteration: 178, decoding loss: 0.030220137909054756, distance cost: 0.009875145740807056\n",
      "iteration: 268, decoding loss: 0.026997819542884827, distance cost: 0.011111048050224781\n",
      "iteration: 272, decoding loss: 0.02609594538807869, distance cost: 0.011532171629369259\n",
      "iteration: 274, decoding loss: 0.024751072749495506, distance cost: 0.011159075424075127\n",
      "iteration: 278, decoding loss: 0.024954304099082947, distance cost: 0.010614308528602123\n",
      "iteration: 279, decoding loss: 0.02529466710984707, distance cost: 0.010040037333965302\n",
      "iteration: 349, decoding loss: 0.021323423832654953, distance cost: 0.012431967072188854\n",
      "iteration: 355, decoding loss: 0.021554071456193924, distance cost: 0.011511280201375484\n",
      "iteration: 356, decoding loss: 0.021173974499106407, distance cost: 0.010804793797433376\n",
      "iteration: 358, decoding loss: 0.020075468346476555, distance cost: 0.01152962539345026\n",
      "iteration: 359, decoding loss: 0.018542202189564705, distance cost: 0.011964085511863232\n",
      "iteration: 361, decoding loss: 0.01897290162742138, distance cost: 0.011475578881800175\n",
      "iteration: 362, decoding loss: 0.01861659623682499, distance cost: 0.010912911035120487\n",
      "iteration: 363, decoding loss: 0.01803368516266346, distance cost: 0.010137888602912426\n",
      "iteration: 365, decoding loss: 0.01774153858423233, distance cost: 0.010364874266088009\n",
      "iteration: 366, decoding loss: 0.01719963550567627, distance cost: 0.010783136822283268\n",
      "iteration: 367, decoding loss: 0.01672455295920372, distance cost: 0.010186541825532913\n",
      "iteration: 370, decoding loss: 0.016363803297281265, distance cost: 0.010166647844016552\n",
      "iteration: 371, decoding loss: 0.01620441861450672, distance cost: 0.009590307250618935\n",
      "iteration: 372, decoding loss: 0.014741732738912106, distance cost: 0.010190877132117748\n",
      "iteration: 373, decoding loss: 0.014505309984087944, distance cost: 0.009375042282044888\n",
      "iteration: 375, decoding loss: 0.014366262592375278, distance cost: 0.009054484777152538\n",
      "iteration: 378, decoding loss: 0.011454359628260136, distance cost: 0.00879276730120182\n",
      "iteration: 382, decoding loss: 0.011462452821433544, distance cost: 0.00812636036425829\n",
      "iteration: 383, decoding loss: 0.010753751732409, distance cost: 0.008508240804076195\n",
      "iteration: 384, decoding loss: 0.01141470018774271, distance cost: 0.007712571416050196\n",
      "iteration: 385, decoding loss: 0.010058806277811527, distance cost: 0.007510934490710497\n",
      "iteration: 387, decoding loss: 0.00933864340186119, distance cost: 0.00755979772657156\n",
      "iteration: 388, decoding loss: 0.009380144998431206, distance cost: 0.007515648379921913\n",
      "iteration: 389, decoding loss: 0.009339657612144947, distance cost: 0.00750536797568202\n",
      "iteration: 390, decoding loss: 0.008484039455652237, distance cost: 0.007377651520073414\n",
      "iteration: 392, decoding loss: 0.008529352955520153, distance cost: 0.007177857682108879\n",
      "iteration: 393, decoding loss: 0.007988142780959606, distance cost: 0.006755572743713856\n",
      "iteration: 395, decoding loss: 0.006730496417731047, distance cost: 0.0067008910700678825\n",
      "iteration: 397, decoding loss: 0.006802461110055447, distance cost: 0.006464051082730293\n",
      "iteration: 399, decoding loss: 0.0065544405952095985, distance cost: 0.006334248930215836\n",
      "iteration: 400, decoding loss: 0.006087928079068661, distance cost: 0.00617662537842989\n",
      "iteration: 403, decoding loss: 0.005321357864886522, distance cost: 0.006639414932578802\n",
      "iteration: 404, decoding loss: 0.0050083487294614315, distance cost: 0.005745405331254005\n",
      "iteration: 407, decoding loss: 0.004755991045385599, distance cost: 0.005740249063819647\n",
      "iteration: 408, decoding loss: 0.004703430458903313, distance cost: 0.005686784163117409\n",
      "iteration: 410, decoding loss: 0.004356318153440952, distance cost: 0.005931176245212555\n",
      "iteration: 411, decoding loss: 0.0040542748756706715, distance cost: 0.0057804458774626255\n",
      "iteration: 412, decoding loss: 0.003961525857448578, distance cost: 0.005807242356240749\n",
      "iteration: 413, decoding loss: 0.0039689382538199425, distance cost: 0.005595238879323006\n",
      "iteration: 415, decoding loss: 0.003979094326496124, distance cost: 0.005393102765083313\n",
      "iteration: 419, decoding loss: 0.0035100653767585754, distance cost: 0.005728875752538443\n",
      "iteration: 420, decoding loss: 0.00338521646335721, distance cost: 0.0056416187435388565\n",
      "iteration: 422, decoding loss: 0.0034503971692174673, distance cost: 0.005260902922600508\n",
      "iteration: 430, decoding loss: 0.0033285010140389204, distance cost: 0.004685041029006243\n",
      "iteration: 608, decoding loss: 0.00448687095195055, distance cost: 0.003463219851255417\n",
      "iteration: 614, decoding loss: 0.004078735131770372, distance cost: 0.003823165548965335\n",
      "iteration: 620, decoding loss: 0.003975456580519676, distance cost: 0.003767378395423293\n",
      "iteration: 621, decoding loss: 0.004183303099125624, distance cost: 0.003217092016711831\n",
      "iteration: 632, decoding loss: 0.003937738481909037, distance cost: 0.0033809358719736338\n",
      "iteration: 792, decoding loss: 0.002801197115331888, distance cost: 0.0043627554550766945\n",
      "iteration: 800, decoding loss: 0.0025968551635742188, distance cost: 0.004078489728271961\n",
      "iteration: 809, decoding loss: 0.002407158724963665, distance cost: 0.004243519157171249\n",
      "iteration: 812, decoding loss: 0.0024832882918417454, distance cost: 0.003928596153855324\n",
      "iteration: 827, decoding loss: 0.0022808534558862448, distance cost: 0.0036618649028241634\n",
      "iteration: 842, decoding loss: 0.00208909809589386, distance cost: 0.003845913102850318\n",
      "iteration: 845, decoding loss: 0.002083254512399435, distance cost: 0.0036788375582545996\n",
      "iteration: 846, decoding loss: 0.0019354599062353373, distance cost: 0.0034453258849680424\n",
      "iteration: 855, decoding loss: 0.0017888284055516124, distance cost: 0.0035748055670410395\n",
      "iteration: 857, decoding loss: 0.0018197160679847002, distance cost: 0.0034369223285466433\n",
      "iteration: 860, decoding loss: 0.0017619677819311619, distance cost: 0.0034920729231089354\n",
      "iteration: 863, decoding loss: 0.0018156798323616385, distance cost: 0.0033359448425471783\n",
      "iteration: 865, decoding loss: 0.001643475377932191, distance cost: 0.0033481174614280462\n",
      "iteration: 868, decoding loss: 0.0016969764837995172, distance cost: 0.00327401515096426\n",
      "iteration: 872, decoding loss: 0.0014796543400734663, distance cost: 0.00340940710157156\n",
      "iteration: 880, decoding loss: 0.0016053436556831002, distance cost: 0.0032248101197183132\n",
      "iteration: 885, decoding loss: 0.0014003034448251128, distance cost: 0.0033672379795461893\n",
      "iteration: 891, decoding loss: 0.0013519555795937777, distance cost: 0.002898901468142867\n",
      "iteration: 938, decoding loss: 0.0013640110846608877, distance cost: 0.002797307213768363\n",
      "iteration: 1088, decoding loss: 0.0017294373828917742, distance cost: 0.002411501482129097\n",
      "iteration: 1091, decoding loss: 0.001619962858967483, distance cost: 0.0023593497462570667\n",
      "iteration: 1100, decoding loss: 0.0015497447457164526, distance cost: 0.002394133945927024\n",
      "iteration: 1105, decoding loss: 0.0014433080796152353, distance cost: 0.0023501403629779816\n",
      "iteration: 1119, decoding loss: 0.001459193998016417, distance cost: 0.0022478902246803045\n",
      "iteration: 1121, decoding loss: 0.0014014302287250757, distance cost: 0.002297967439517379\n",
      "iteration: 1122, decoding loss: 0.0012920165900141, distance cost: 0.001996283885091543\n",
      "iteration: 1139, decoding loss: 0.0012531543616205454, distance cost: 0.002021420281380415\n",
      "iteration: 1144, decoding loss: 0.00123510486446321, distance cost: 0.0020152051001787186\n",
      "iteration: 1149, decoding loss: 0.0011533851502463222, distance cost: 0.0020914794877171516\n",
      "iteration: 1150, decoding loss: 0.001112833502702415, distance cost: 0.0018665873212739825\n",
      "iteration: 1171, decoding loss: 0.0010161342797800899, distance cost: 0.0019163566175848246\n",
      "iteration: 1207, decoding loss: 0.0009538668091408908, distance cost: 0.001963871531188488\n",
      "iteration: 1421, decoding loss: 0.0010964196408167481, distance cost: 0.0017452341271564364\n",
      "iteration: 1432, decoding loss: 0.0011490039760246873, distance cost: 0.0016786555061116815\n",
      "iteration: 1434, decoding loss: 0.0010794224217534065, distance cost: 0.001657905988395214\n",
      "iteration: 1435, decoding loss: 0.0011194358812645078, distance cost: 0.0015297121135517955\n",
      "iteration: 1446, decoding loss: 0.001030819141305983, distance cost: 0.0014888168079778552\n",
      "iteration: 1451, decoding loss: 0.0010119294747710228, distance cost: 0.0014584676828235388\n",
      "iteration: 1452, decoding loss: 0.00099982472602278, distance cost: 0.0013410812243819237\n",
      "iteration: 1461, decoding loss: 0.0009450808865949512, distance cost: 0.0013942085206508636\n",
      "iteration: 1462, decoding loss: 0.0009505786001682281, distance cost: 0.0012838264228776097\n",
      "iteration: 1466, decoding loss: 0.0008864470873959363, distance cost: 0.001224971143528819\n",
      "iteration: 1471, decoding loss: 0.0008825594559311867, distance cost: 0.0012147080851718783\n",
      "iteration: 1477, decoding loss: 0.0008760351338423789, distance cost: 0.0011824510293081403\n",
      "iteration: 1478, decoding loss: 0.0009042015881277621, distance cost: 0.0011078978423029184\n",
      "iteration: 1479, decoding loss: 0.000859077728819102, distance cost: 0.001110943267121911\n",
      "iteration: 1485, decoding loss: 0.0008209507213905454, distance cost: 0.0011389714200049639\n",
      "iteration: 1486, decoding loss: 0.0008785800309851766, distance cost: 0.0010479548946022987\n",
      "iteration: 1494, decoding loss: 0.0007372985710389912, distance cost: 0.001115895458497107\n",
      "iteration: 1498, decoding loss: 0.000750894658267498, distance cost: 0.0010586872231215239\n",
      "iteration: 1501, decoding loss: 0.0007884755614213645, distance cost: 0.0010185677092522383\n",
      "iteration: 1502, decoding loss: 0.0007868506363593042, distance cost: 0.0010038886684924364\n",
      "iteration: 1503, decoding loss: 0.0007757442654110491, distance cost: 0.0009561959886923432\n",
      "iteration: 1506, decoding loss: 0.0007828457746654749, distance cost: 0.0009182412177324295\n",
      "iteration: 1512, decoding loss: 0.0007538168574683368, distance cost: 0.0009346447768621147\n",
      "iteration: 1514, decoding loss: 0.000784603413194418, distance cost: 0.0009009568602778018\n",
      "iteration: 1515, decoding loss: 0.0007566376007162035, distance cost: 0.0008969887858256698\n",
      "iteration: 1521, decoding loss: 0.0007960843504406512, distance cost: 0.0007855189614929259\n",
      "iteration: 1523, decoding loss: 0.0007379919406957924, distance cost: 0.0008269657264463603\n",
      "iteration: 1535, decoding loss: 0.0007583892438560724, distance cost: 0.0007547474233433604\n",
      "iteration: 1541, decoding loss: 0.0007513170130550861, distance cost: 0.0007463236688636243\n",
      "iteration: 1552, decoding loss: 0.0007124898256734014, distance cost: 0.0007597861695103347\n",
      "iteration: 1555, decoding loss: 0.0007368721999228001, distance cost: 0.0007024912047199905\n",
      "iteration: 1567, decoding loss: 0.0007473077857866883, distance cost: 0.0006904652691446245\n",
      "iteration: 1576, decoding loss: 0.0007207650924101472, distance cost: 0.0007041501812636852\n",
      "iteration: 1593, decoding loss: 0.0007847656379453838, distance cost: 0.000629634887445718\n",
      "iteration: 1953, decoding loss: 0.0006512835389003158, distance cost: 0.0007609663298353553\n",
      "iteration: 1975, decoding loss: 0.0006257981294766068, distance cost: 0.0007003149366937578\n",
      "iteration: 1990, decoding loss: 0.0006629234994761646, distance cost: 0.0006588645628653467\n",
      "iteration: 1994, decoding loss: 0.0005774209857918322, distance cost: 0.0007275473326444626\n",
      "iteration: 2007, decoding loss: 0.0006262385286390781, distance cost: 0.0006752702174708247\n",
      "iteration: 2010, decoding loss: 0.0005857062642462552, distance cost: 0.000646379659883678\n",
      "iteration: 2019, decoding loss: 0.0005732209538109601, distance cost: 0.0006194909219630063\n",
      "iteration: 2047, decoding loss: 0.0005380850052461028, distance cost: 0.0006286856369115412\n",
      "iteration: 2456, decoding loss: 0.00045253284042701125, distance cost: 0.0006841784925200045\n",
      "iteration: 2461, decoding loss: 0.00041733772377483547, distance cost: 0.000702571589499712\n",
      "iteration: 2466, decoding loss: 0.0004042700747959316, distance cost: 0.0006989753455854952\n",
      "iteration: 2472, decoding loss: 0.00040740336407907307, distance cost: 0.0006930039380677044\n",
      "iteration: 2477, decoding loss: 0.0004158811061643064, distance cost: 0.0006774698849767447\n",
      "iteration: 2478, decoding loss: 0.00042284117080271244, distance cost: 0.0006482789176516235\n",
      "iteration: 2479, decoding loss: 0.0004108572320546955, distance cost: 0.0006554859573952854\n",
      "iteration: 2496, decoding loss: 0.00038836125168018043, distance cost: 0.0006718888762407005\n",
      "iteration: 2498, decoding loss: 0.00039656111039221287, distance cost: 0.0006554084247909486\n",
      "iteration: 2501, decoding loss: 0.00038495505577884614, distance cost: 0.0006382212741300464\n",
      "iteration: 2511, decoding loss: 0.00038041602238081396, distance cost: 0.0006117457523941994\n",
      "iteration: 2514, decoding loss: 0.00035844018566422164, distance cost: 0.0005824473919346929\n",
      "iteration: 2530, decoding loss: 0.00035973472404293716, distance cost: 0.0005634050467051566\n",
      "iteration: 2546, decoding loss: 0.00036413795896805823, distance cost: 0.0005471554468385875\n",
      "iteration: 2554, decoding loss: 0.0003646607219707221, distance cost: 0.0005306647508405149\n",
      "iteration: 2559, decoding loss: 0.00034134124871343374, distance cost: 0.0005313865840435028\n",
      "iteration: 2563, decoding loss: 0.0003130199038423598, distance cost: 0.0005222108447924256\n"
     ]
    }
   ],
   "source": [
    "encoder, decoder = s1_direct_product_generator.train(1, 3, device, n_training_iterations=3000)\n",
    "\n",
    "angles = np.arange(start=0, stop=2 * np.pi, step=0.01)\n",
    "with torch.no_grad():\n",
    "    points = geometry_util.torch_angles_to_ring(torch.tensor(angles, dtype=torch.get_default_dtype()).to(device))\n",
    "    points = torch.unsqueeze(points, -2)\n",
    "    test_embedding = encoder(points)\n",
    "test_embedding = test_embedding.cpu().numpy()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The shape it generates should be pretty much random, as there is nothing in the loss function we use that encourages a specific shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7fb8fc2bc3a0>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "proj_fig = plt.figure()\n",
    "proj_axs = proj_fig.add_subplot(projection=\"3d\")\n",
    "proj_axs.scatter(test_embedding[:, 0], test_embedding[:, 1], test_embedding[:, 2], cmap=\"hsv\", c=angles)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's generate a higher dimensional ring"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0, decoding loss: 0.9128285050392151, distance cost: 0.002092661103233695\n",
      "iteration: 1, decoding loss: 0.6880248785018921, distance cost: 0.04595998302102089\n",
      "iteration: 2, decoding loss: 0.4236714541912079, distance cost: 0.06351182609796524\n",
      "iteration: 18, decoding loss: 0.3824080526828766, distance cost: 0.04834365472197533\n",
      "iteration: 19, decoding loss: 0.33976036310195923, distance cost: 0.04819042608141899\n",
      "iteration: 48, decoding loss: 0.3084816336631775, distance cost: 0.07775271683931351\n",
      "iteration: 49, decoding loss: 0.267177939414978, distance cost: 0.07470875233411789\n",
      "iteration: 50, decoding loss: 0.22744251787662506, distance cost: 0.06605216860771179\n",
      "iteration: 51, decoding loss: 0.20574626326560974, distance cost: 0.0672905370593071\n",
      "iteration: 52, decoding loss: 0.18668073415756226, distance cost: 0.07650379091501236\n",
      "iteration: 53, decoding loss: 0.18195901811122894, distance cost: 0.06642839312553406\n",
      "iteration: 63, decoding loss: 0.20828230679035187, distance cost: 0.033936526626348495\n",
      "iteration: 64, decoding loss: 0.19881033897399902, distance cost: 0.03505178913474083\n",
      "iteration: 65, decoding loss: 0.15601512789726257, distance cost: 0.0296550951898098\n",
      "iteration: 66, decoding loss: 0.1240956112742424, distance cost: 0.029905244708061218\n",
      "iteration: 67, decoding loss: 0.1001405194401741, distance cost: 0.02562863752245903\n",
      "iteration: 68, decoding loss: 0.08937335014343262, distance cost: 0.026300828903913498\n",
      "iteration: 69, decoding loss: 0.07435856759548187, distance cost: 0.02406861074268818\n",
      "iteration: 70, decoding loss: 0.07265971601009369, distance cost: 0.024665649980306625\n",
      "iteration: 71, decoding loss: 0.06585975736379623, distance cost: 0.023729585111141205\n",
      "iteration: 100, decoding loss: 0.06499525159597397, distance cost: 0.02455134317278862\n",
      "iteration: 101, decoding loss: 0.05586175620555878, distance cost: 0.028197627514600754\n",
      "iteration: 102, decoding loss: 0.05771414563059807, distance cost: 0.02553371526300907\n",
      "iteration: 103, decoding loss: 0.05344712361693382, distance cost: 0.02766607329249382\n",
      "iteration: 104, decoding loss: 0.051208991557359695, distance cost: 0.02813466265797615\n",
      "iteration: 105, decoding loss: 0.048565272241830826, distance cost: 0.027529556304216385\n",
      "iteration: 106, decoding loss: 0.045808736234903336, distance cost: 0.02506183832883835\n",
      "iteration: 107, decoding loss: 0.04352332651615143, distance cost: 0.02731349878013134\n",
      "iteration: 108, decoding loss: 0.04340885207056999, distance cost: 0.02428848296403885\n",
      "iteration: 113, decoding loss: 0.038549259305000305, distance cost: 0.028048165142536163\n",
      "iteration: 147, decoding loss: 0.028689319267868996, distance cost: 0.036511316895484924\n",
      "iteration: 151, decoding loss: 0.02758372388780117, distance cost: 0.03638360649347305\n",
      "iteration: 172, decoding loss: 0.024941083043813705, distance cost: 0.03888595849275589\n",
      "iteration: 179, decoding loss: 0.024706527590751648, distance cost: 0.03770057111978531\n",
      "iteration: 182, decoding loss: 0.025523336604237556, distance cost: 0.0336785763502121\n",
      "iteration: 198, decoding loss: 0.031152792274951935, distance cost: 0.027684282511472702\n",
      "iteration: 200, decoding loss: 0.03224436938762665, distance cost: 0.024862201884388924\n",
      "iteration: 202, decoding loss: 0.028568243607878685, distance cost: 0.02801232971251011\n",
      "iteration: 203, decoding loss: 0.026401635259389877, distance cost: 0.028389947488904\n",
      "iteration: 204, decoding loss: 0.028179215267300606, distance cost: 0.02557978220283985\n",
      "iteration: 205, decoding loss: 0.02831995114684105, distance cost: 0.02382926642894745\n",
      "iteration: 206, decoding loss: 0.024145055562257767, distance cost: 0.026656268164515495\n",
      "iteration: 207, decoding loss: 0.023584317415952682, distance cost: 0.02403886802494526\n",
      "iteration: 208, decoding loss: 0.022476600483059883, distance cost: 0.023515542969107628\n",
      "iteration: 209, decoding loss: 0.021467404440045357, distance cost: 0.021963413804769516\n",
      "iteration: 211, decoding loss: 0.02061864361166954, distance cost: 0.020906968042254448\n",
      "iteration: 212, decoding loss: 0.01907615177333355, distance cost: 0.020840249955654144\n",
      "iteration: 214, decoding loss: 0.020221982151269913, distance cost: 0.018704373389482498\n",
      "iteration: 216, decoding loss: 0.01873224973678589, distance cost: 0.019193479791283607\n",
      "iteration: 217, decoding loss: 0.017165405675768852, distance cost: 0.019580194726586342\n",
      "iteration: 219, decoding loss: 0.016480881720781326, distance cost: 0.01940883882343769\n",
      "iteration: 220, decoding loss: 0.016546525061130524, distance cost: 0.018434850499033928\n",
      "iteration: 222, decoding loss: 0.016335051506757736, distance cost: 0.01679963804781437\n",
      "iteration: 224, decoding loss: 0.016442634165287018, distance cost: 0.015554552897810936\n",
      "iteration: 225, decoding loss: 0.01480571273714304, distance cost: 0.01517272274941206\n",
      "iteration: 227, decoding loss: 0.01512111909687519, distance cost: 0.014774958603084087\n",
      "iteration: 229, decoding loss: 0.014452751725912094, distance cost: 0.01281902939081192\n",
      "iteration: 232, decoding loss: 0.014464116655290127, distance cost: 0.012040264904499054\n",
      "iteration: 234, decoding loss: 0.012848731130361557, distance cost: 0.01303577795624733\n",
      "iteration: 236, decoding loss: 0.01256471686065197, distance cost: 0.012162009254097939\n",
      "iteration: 238, decoding loss: 0.011507130227982998, distance cost: 0.012155565433204174\n",
      "iteration: 240, decoding loss: 0.011497101746499538, distance cost: 0.011349241249263287\n",
      "iteration: 241, decoding loss: 0.009886179119348526, distance cost: 0.01246143039315939\n",
      "iteration: 245, decoding loss: 0.010348821058869362, distance cost: 0.010315792635083199\n",
      "iteration: 252, decoding loss: 0.010048969648778439, distance cost: 0.010230532847344875\n",
      "iteration: 254, decoding loss: 0.009927662089467049, distance cost: 0.00943015143275261\n",
      "iteration: 258, decoding loss: 0.009798713028430939, distance cost: 0.009146073833107948\n",
      "iteration: 267, decoding loss: 0.009890812449157238, distance cost: 0.008951185271143913\n",
      "iteration: 270, decoding loss: 0.01010972261428833, distance cost: 0.007817327044904232\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m encoder, decoder \u001B[38;5;241m=\u001B[39m \u001B[43ms1_direct_product_generator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m24\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_training_iterations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3000\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m angles \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marange(start\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, stop\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39mpi, step\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n",
      "File \u001B[0;32m~/RNN_Manifold/s1_direct_product_generator.py:41\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(manifold_dimension, embedding_dimension, device, encoder_hidden_dim, encoder_n_hidden, decoder_hidden_dim, decoder_n_hidden, integration_resamples, n_points_compare, batch_size, n_training_iterations, loss_stop_thresh)\u001B[0m\n\u001B[1;32m     38\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     39\u001B[0m opt\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m---> 41\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m loss \u001B[38;5;241m<\u001B[39m best_loss:\n\u001B[1;32m     42\u001B[0m     best_loss \u001B[38;5;241m=\u001B[39m loss\n\u001B[1;32m     43\u001B[0m     best_encoder \u001B[38;5;241m=\u001B[39m copy\u001B[38;5;241m.\u001B[39mdeepcopy(encoder_net)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "encoder, decoder = s1_direct_product_generator.train(1, 24, device, n_training_iterations=3000)\n",
    "\n",
    "angles = np.arange(start=0, stop=2 * np.pi, step=0.01)\n",
    "with torch.no_grad():\n",
    "    points = geometry_util.torch_angles_to_ring(torch.tensor(angles, dtype=torch.get_default_dtype()).to(device))\n",
    "    points = torch.unsqueeze(points, -2)\n",
    "    high_d_generated_ring_data = encoder(points)\n",
    "high_d_generated_ring_data = high_d_generated_ring_data.cpu().numpy()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And then decode it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "high_d_generated_ring_data = high_d_generated_ring_data/np.mean(np.abs(high_d_generated_ring_data))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder, decoder = s1_direct_product_decoder.train(data=high_d_generated_ring_data, manifold_dim=1, device=device,\n",
    "                                                   n_training_iterations=3000, decoder_weight=10, order_red_weight=0.1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    decoded_points, decoded_angles = decoder(torch.tensor(high_d_generated_ring_data, dtype=torch.get_default_dtype()).to(device))\n",
    "\n",
    "predicted_phases = torch.squeeze(decoded_angles).cpu().numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def reference_phases(phases):\n",
    "    phases_refd = phases - phases[0]\n",
    "    phases_refd = np.arctan2(np.sin(phases_refd), np.cos(phases_refd))\n",
    "    return phases_refd * np.sign(phases_refd[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compare_to_ground_truth(predicted_phases, ground_truth_phases, plot_ax):\n",
    "    refd_test_phases = reference_phases(predicted_phases)\n",
    "    refd_true_phases = reference_phases(ground_truth_phases)\n",
    "    line = np.arange(start=-np.pi, stop=np.pi, step=0.01)\n",
    "    plot_ax.scatter(refd_true_phases, refd_test_phases)\n",
    "    plot_ax.plot(line, line, color=\"black\", linestyle=\"--\", label=\"y=x\")\n",
    "    plot_ax.set_xlabel(\"True Phase\")\n",
    "    plot_ax.set_ylabel(\"Found Phase\")\n",
    "    return refd_test_phases, refd_true_phases\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "refd_predicted_phases, refd_true_phases = compare_to_ground_truth(predicted_phases, angles, ax)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's do a harder problem. Let's decode noisy data generated by a dynamic system. First, the dynamics. We will use a typical ring attractor model,"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def conv_circ(signal, ker):\n",
    "    return np.fft.ifft(np.einsum(\"ij, j -> ij\", np.fft.fft(signal, axis=1), np.fft.fft(ker)), axis=1)\n",
    "\n",
    "\n",
    "def cosine_kernel(w_0, w_1, N):\n",
    "    step = 2/(N)\n",
    "    grid = np.arange(start=0, stop=2, step=step) * np.pi\n",
    "    weights = -w_0 + w_1 * np.cos(grid)\n",
    "    return weights\n",
    "\n",
    "\n",
    "def ring_attractor_dynamics(state, kernel, bias_vec, nonlin_fn):\n",
    "    if len(np.shape(state)) == 1:\n",
    "        state = np.expand_dims(state, -1)\n",
    "    state = np.transpose(state)\n",
    "    return np.transpose(-state + nonlin_fn(conv_circ(state, kernel) + bias_vec))\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return np.exp(x)/(np.exp(x) + 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate some samples of equalibrium states. We will generate around 50, to make things interesting."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N = 2 ** 7\n",
    "n_samples = 50\n",
    "\n",
    "init_conds = np.random.uniform(-1, 1, (n_samples, N)).astype(np.complex)\n",
    "\n",
    "w_0 = 1\n",
    "w_1 = 1\n",
    "kernel = cosine_kernel(w_0, w_1, N)\n",
    "\n",
    "\n",
    "def run_equilibriation(init_conds):\n",
    "    soln = integrate.solve_ivp(lambda _, y: ring_attractor_dynamics(y, kernel, np.zeros(N), sigmoid),\n",
    "                               [0, 20], init_conds, vectorized=True)\n",
    "    return soln.y[:, -1]\n",
    "\n",
    "\n",
    "p = mp.Pool()\n",
    "solns = np.array(p.map(run_equilibriation, init_conds))\n",
    "p.close()\n",
    "p.join()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add some noise"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ring_attractor_data = np.real(solns/np.mean(np.abs(solns)))\n",
    "noisy_ring_attractor_data = ring_attractor_data + np.random.normal(0, np.max(ring_attractor_data)/15, np.shape(ring_attractor_data))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note down the ground truth phases"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true_ring_att_phases = (np.argmax(ring_attractor_data, axis=1)/N) * 2 * np.pi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(noisy_ring_attractor_data, aspect=\"auto\")\n",
    "ax.set_title(\"Raw activation data\")\n",
    "ax.set_xlabel(\"Neuron Index\")\n",
    "ax.set_ylabel(\"Datapoint\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now decode"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder, decoder = s1_direct_product_decoder.train(data=noisy_ring_attractor_data, manifold_dim=1, device=device,\n",
    "                                                   n_training_iterations=3000, decoder_weight=10, order_red_weight=0.1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    decoded_points, decoded_angles = decoder(torch.tensor(noisy_ring_attractor_data, dtype=torch.get_default_dtype()).to(device))\n",
    "\n",
    "ring_att_predicted_phases = torch.squeeze(decoded_angles).cpu().numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "refd_ring_att_predicted_phases, refd_ring_att_true_phases = compare_to_ground_truth(ring_att_predicted_phases, true_ring_att_phases, ax)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
