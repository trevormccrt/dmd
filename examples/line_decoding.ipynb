{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb15030a-6432-4d64-8418-9b9effd3ae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import decode_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd6770d2-3b3c-4ab5-9f89-1a68e22b9eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"using {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd841964-ac55-4a78-aad9-64e50efaf281",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_phases = np.linspace(start=-np.pi, stop=np.pi, num=200)\n",
    "line_points = np.zeros((len(line_phases), 2))\n",
    "line_points[:, 0] = line_phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a3bd507-f664-446e-830c-1bbc28a4d393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0, decoding loss: 1.6627464294433594, distance cost: 0.0014985838206484914, order reduction: 0.07612977176904678\n",
      "iteration: 16, decoding loss: 0.9793140888214111, distance cost: 0.3440300524234772, order reduction: 0.062506303191185\n",
      "iteration: 19, decoding loss: 1.188212513923645, distance cost: 0.1502058506011963, order reduction: 0.02149992436170578\n",
      "iteration: 25, decoding loss: 1.0661250352859497, distance cost: 0.10012292861938477, order reduction: 0.008631045930087566\n",
      "iteration: 26, decoding loss: 0.9026782512664795, distance cost: 0.11539090424776077, order reduction: 0.027406316250562668\n",
      "iteration: 30, decoding loss: 0.6684779524803162, distance cost: 0.15661105513572693, order reduction: 0.18931779265403748\n",
      "iteration: 31, decoding loss: 0.5805450081825256, distance cost: 0.08133168518543243, order reduction: 0.053802087903022766\n",
      "iteration: 37, decoding loss: 0.6293122172355652, distance cost: 0.0120597118511796, order reduction: 0.07089436799287796\n",
      "iteration: 39, decoding loss: 0.6245961785316467, distance cost: 0.01957043632864952, order reduction: 0.049445901066064835\n",
      "iteration: 45, decoding loss: 0.5162405967712402, distance cost: 0.017340946942567825, order reduction: 0.023826299235224724\n",
      "iteration: 56, decoding loss: 0.5140788555145264, distance cost: 0.010627567768096924, order reduction: 0.013545779511332512\n",
      "iteration: 59, decoding loss: 0.49286335706710815, distance cost: 0.026282893493771553, order reduction: 0.011704174801707268\n",
      "iteration: 61, decoding loss: 0.4674476683139801, distance cost: 0.016645008698105812, order reduction: 0.010628429241478443\n",
      "iteration: 66, decoding loss: 0.46572744846343994, distance cost: 0.01834157295525074, order reduction: 0.008899854496121407\n",
      "iteration: 74, decoding loss: 0.4526045620441437, distance cost: 0.020729610696434975, order reduction: 0.007391601800918579\n",
      "iteration: 82, decoding loss: 0.4513072371482849, distance cost: 0.007638636976480484, order reduction: 0.00755345867946744\n",
      "iteration: 213, decoding loss: 0.37281471490859985, distance cost: 0.07751832902431488, order reduction: 0.007764921523630619\n",
      "iteration: 214, decoding loss: 0.34996068477630615, distance cost: 0.060769982635974884, order reduction: 0.009707679972052574\n",
      "iteration: 215, decoding loss: 0.3271491229534149, distance cost: 0.05573941394686699, order reduction: 0.008050650358200073\n",
      "iteration: 217, decoding loss: 0.2681145966053009, distance cost: 0.08122052252292633, order reduction: 0.006933860946446657\n",
      "iteration: 218, decoding loss: 0.25918933749198914, distance cost: 0.07589151710271835, order reduction: 0.005549819208681583\n",
      "iteration: 219, decoding loss: 0.25463250279426575, distance cost: 0.06201722100377083, order reduction: 0.00946118775755167\n",
      "iteration: 222, decoding loss: 0.26355984807014465, distance cost: 0.05133522301912308, order reduction: 0.005636975169181824\n",
      "iteration: 223, decoding loss: 0.2567717432975769, distance cost: 0.03620581701397896, order reduction: 0.010097647085785866\n",
      "iteration: 225, decoding loss: 0.2522951662540436, distance cost: 0.04574769735336304, order reduction: 0.003098216373473406\n",
      "iteration: 226, decoding loss: 0.23629702627658844, distance cost: 0.033334411680698395, order reduction: 0.00869856309145689\n",
      "iteration: 229, decoding loss: 0.23381538689136505, distance cost: 0.030853455886244774, order reduction: 0.0070197428576648235\n",
      "iteration: 230, decoding loss: 0.22664162516593933, distance cost: 0.032617051154375076, order reduction: 0.007480504922568798\n",
      "iteration: 231, decoding loss: 0.2248527705669403, distance cost: 0.02906486950814724, order reduction: 0.008736821822822094\n",
      "iteration: 232, decoding loss: 0.21512410044670105, distance cost: 0.033373720943927765, order reduction: 0.00543400039896369\n",
      "iteration: 234, decoding loss: 0.19673486053943634, distance cost: 0.03499620407819748, order reduction: 0.010200122371315956\n",
      "iteration: 235, decoding loss: 0.19831271469593048, distance cost: 0.03333498165011406, order reduction: 0.005454419646412134\n",
      "iteration: 236, decoding loss: 0.18192346394062042, distance cost: 0.028277337551116943, order reduction: 0.004884651862084866\n",
      "iteration: 239, decoding loss: 0.170253187417984, distance cost: 0.03402942791581154, order reduction: 0.007940787822008133\n",
      "iteration: 241, decoding loss: 0.16822953522205353, distance cost: 0.026994284242391586, order reduction: 0.009973122738301754\n",
      "iteration: 242, decoding loss: 0.16358093917369843, distance cost: 0.03333425149321556, order reduction: 0.00501260906457901\n",
      "iteration: 243, decoding loss: 0.14693890511989594, distance cost: 0.038938652724027634, order reduction: 0.008791389875113964\n",
      "iteration: 245, decoding loss: 0.15568993985652924, distance cost: 0.030234169214963913, order reduction: 0.006138962227851152\n",
      "iteration: 246, decoding loss: 0.15125545859336853, distance cost: 0.025130776688456535, order reduction: 0.010470562614500523\n",
      "iteration: 247, decoding loss: 0.1549926996231079, distance cost: 0.02248586155474186, order reduction: 0.004844814073294401\n",
      "iteration: 249, decoding loss: 0.13648904860019684, distance cost: 0.026994915679097176, order reduction: 0.007103957701474428\n",
      "iteration: 250, decoding loss: 0.13416516780853271, distance cost: 0.021788960322737694, order reduction: 0.007269582245498896\n",
      "iteration: 253, decoding loss: 0.11850432306528091, distance cost: 0.022197961807250977, order reduction: 0.006385508459061384\n",
      "iteration: 254, decoding loss: 0.12069631367921829, distance cost: 0.019301215186715126, order reduction: 0.006441295146942139\n",
      "iteration: 256, decoding loss: 0.11337745189666748, distance cost: 0.017008643597364426, order reduction: 0.012927509844303131\n",
      "iteration: 257, decoding loss: 0.1147792860865593, distance cost: 0.015583181753754616, order reduction: 0.012132314965128899\n",
      "iteration: 259, decoding loss: 0.11499065160751343, distance cost: 0.014858159236609936, order reduction: 0.0076059335842728615\n",
      "iteration: 260, decoding loss: 0.11189720034599304, distance cost: 0.013184107840061188, order reduction: 0.00704566715285182\n",
      "iteration: 262, decoding loss: 0.10759858042001724, distance cost: 0.01086459867656231, order reduction: 0.005144073627889156\n",
      "iteration: 264, decoding loss: 0.1056101843714714, distance cost: 0.011198549531400204, order reduction: 0.006283101160079241\n",
      "iteration: 265, decoding loss: 0.09844888746738434, distance cost: 0.0159856379032135, order reduction: 0.007876005955040455\n",
      "iteration: 266, decoding loss: 0.09992510825395584, distance cost: 0.012302554212510586, order reduction: 0.0068302880972623825\n",
      "iteration: 268, decoding loss: 0.08636713027954102, distance cost: 0.011472050100564957, order reduction: 0.011012735776603222\n",
      "iteration: 271, decoding loss: 0.08709010481834412, distance cost: 0.009485754184424877, order reduction: 0.006308560725301504\n",
      "iteration: 273, decoding loss: 0.08220035582780838, distance cost: 0.008404537104070187, order reduction: 0.006152017042040825\n",
      "iteration: 275, decoding loss: 0.07888364046812057, distance cost: 0.008786019869148731, order reduction: 0.005964618641883135\n",
      "iteration: 279, decoding loss: 0.07424414157867432, distance cost: 0.010188011452555656, order reduction: 0.006367675494402647\n",
      "iteration: 280, decoding loss: 0.07523412257432938, distance cost: 0.007099746726453304, order reduction: 0.0070213740691542625\n",
      "iteration: 282, decoding loss: 0.07165785878896713, distance cost: 0.006478321738541126, order reduction: 0.009363573975861073\n",
      "iteration: 283, decoding loss: 0.07161836326122284, distance cost: 0.0061996569857001305, order reduction: 0.007701352704316378\n",
      "iteration: 284, decoding loss: 0.07052505761384964, distance cost: 0.0065778698772192, order reduction: 0.006926712114363909\n",
      "iteration: 285, decoding loss: 0.06131897494196892, distance cost: 0.007801251485943794, order reduction: 0.0059466175734996796\n",
      "iteration: 288, decoding loss: 0.06288745999336243, distance cost: 0.00623736809939146, order reduction: 0.005812834948301315\n",
      "iteration: 290, decoding loss: 0.06177898868918419, distance cost: 0.0066762357018888, order reduction: 0.005736292339861393\n",
      "iteration: 291, decoding loss: 0.0599091537296772, distance cost: 0.005282865837216377, order reduction: 0.0071538169868290424\n",
      "iteration: 292, decoding loss: 0.05849966034293175, distance cost: 0.005731923505663872, order reduction: 0.007176395505666733\n",
      "iteration: 294, decoding loss: 0.05647869408130646, distance cost: 0.00535434577614069, order reduction: 0.008523048833012581\n",
      "iteration: 296, decoding loss: 0.05426701903343201, distance cost: 0.00480093015357852, order reduction: 0.007058215793222189\n",
      "iteration: 297, decoding loss: 0.05264578387141228, distance cost: 0.0054539768025279045, order reduction: 0.0068451398983597755\n",
      "iteration: 298, decoding loss: 0.05251501128077507, distance cost: 0.004937703255563974, order reduction: 0.0046362848952412605\n",
      "iteration: 299, decoding loss: 0.04932331293821335, distance cost: 0.005629447288811207, order reduction: 0.007099386770278215\n",
      "iteration: 300, decoding loss: 0.05074174702167511, distance cost: 0.0045392559841275215, order reduction: 0.006191334221512079\n",
      "iteration: 302, decoding loss: 0.04893580079078674, distance cost: 0.004180687014013529, order reduction: 0.004988087806850672\n",
      "iteration: 303, decoding loss: 0.045516859740018845, distance cost: 0.005260834936052561, order reduction: 0.005265750456601381\n",
      "iteration: 304, decoding loss: 0.04317241534590721, distance cost: 0.005204082932323217, order reduction: 0.005658789072185755\n",
      "iteration: 305, decoding loss: 0.040979549288749695, distance cost: 0.004792458843439817, order reduction: 0.0052166590467095375\n",
      "iteration: 308, decoding loss: 0.038776956498622894, distance cost: 0.004197625909000635, order reduction: 0.0065147764980793\n",
      "iteration: 310, decoding loss: 0.03899092599749565, distance cost: 0.0036003838758915663, order reduction: 0.006847668904811144\n",
      "iteration: 312, decoding loss: 0.038078565150499344, distance cost: 0.0024079717695713043, order reduction: 0.003949426580220461\n",
      "iteration: 314, decoding loss: 0.037100594490766525, distance cost: 0.0024673263542354107, order reduction: 0.004090077243745327\n",
      "iteration: 317, decoding loss: 0.033823154866695404, distance cost: 0.002688746200874448, order reduction: 0.0052386256866157055\n",
      "iteration: 319, decoding loss: 0.031811121851205826, distance cost: 0.003434028709307313, order reduction: 0.005837221164256334\n",
      "iteration: 320, decoding loss: 0.031932804733514786, distance cost: 0.0037418308202177286, order reduction: 0.00539217796176672\n",
      "iteration: 321, decoding loss: 0.0285008754581213, distance cost: 0.003428754396736622, order reduction: 0.00435454910621047\n",
      "iteration: 322, decoding loss: 0.028670644387602806, distance cost: 0.0025255661457777023, order reduction: 0.004411664791405201\n",
      "iteration: 325, decoding loss: 0.027234604582190514, distance cost: 0.0019943297374993563, order reduction: 0.004299728665500879\n",
      "iteration: 327, decoding loss: 0.026821499690413475, distance cost: 0.0022767335176467896, order reduction: 0.002866466762498021\n",
      "iteration: 328, decoding loss: 0.024802792817354202, distance cost: 0.0024696295149624348, order reduction: 0.003248595865443349\n",
      "iteration: 331, decoding loss: 0.022293925285339355, distance cost: 0.0017490196041762829, order reduction: 0.003594747744500637\n",
      "iteration: 333, decoding loss: 0.021823834627866745, distance cost: 0.0012883084127679467, order reduction: 0.003679586574435234\n",
      "iteration: 336, decoding loss: 0.01844254694879055, distance cost: 0.0013744349125772715, order reduction: 0.002771426923573017\n",
      "iteration: 339, decoding loss: 0.015890108421444893, distance cost: 0.0017358561744913459, order reduction: 0.0029859791975468397\n",
      "iteration: 342, decoding loss: 0.015962902456521988, distance cost: 0.0011335902381688356, order reduction: 0.002441577147692442\n",
      "iteration: 345, decoding loss: 0.015738604590296745, distance cost: 0.0008425470441579819, order reduction: 0.0015430374769493937\n",
      "iteration: 348, decoding loss: 0.014114687219262123, distance cost: 0.0010418944293633103, order reduction: 0.0018628479447215796\n",
      "iteration: 349, decoding loss: 0.013010851107537746, distance cost: 0.000900538987480104, order reduction: 0.0017004541587084532\n",
      "iteration: 351, decoding loss: 0.013045310974121094, distance cost: 0.0009593438589945436, order reduction: 0.0015959577867761254\n",
      "iteration: 352, decoding loss: 0.012546628713607788, distance cost: 0.0008336475002579391, order reduction: 0.0013482829090207815\n",
      "iteration: 354, decoding loss: 0.012138895690441132, distance cost: 0.0006939281011000276, order reduction: 0.0013454115251079202\n",
      "iteration: 356, decoding loss: 0.010869569145143032, distance cost: 0.0007226593443192542, order reduction: 0.0018302841344848275\n",
      "iteration: 357, decoding loss: 0.009885097853839397, distance cost: 0.0007089171558618546, order reduction: 0.0014869602164253592\n",
      "iteration: 358, decoding loss: 0.009337351657450199, distance cost: 0.0006900790031068027, order reduction: 0.001355531276203692\n",
      "iteration: 359, decoding loss: 0.009600761346518993, distance cost: 0.0005914721987210214, order reduction: 0.0011779599590227008\n",
      "iteration: 363, decoding loss: 0.009739040397107601, distance cost: 0.0005205730558373034, order reduction: 0.0009574283030815423\n",
      "iteration: 364, decoding loss: 0.008280630223453045, distance cost: 0.0005485794972628355, order reduction: 0.0011518936371430755\n",
      "iteration: 366, decoding loss: 0.007517232093960047, distance cost: 0.0006286356947384775, order reduction: 0.001078384113498032\n",
      "iteration: 367, decoding loss: 0.007459154352545738, distance cost: 0.00046700105303898454, order reduction: 0.0009441320435144007\n",
      "iteration: 369, decoding loss: 0.007663246244192123, distance cost: 0.00027661092462949455, order reduction: 0.000790877384133637\n",
      "iteration: 372, decoding loss: 0.006326018832623959, distance cost: 0.00030884603620506823, order reduction: 0.0008470516186207533\n",
      "iteration: 374, decoding loss: 0.005625905003398657, distance cost: 0.00043296441435813904, order reduction: 0.000684144557453692\n",
      "iteration: 377, decoding loss: 0.0055095842108130455, distance cost: 0.0002334640739718452, order reduction: 0.000631433620583266\n",
      "iteration: 378, decoding loss: 0.0053308503702282906, distance cost: 0.0001638554676901549, order reduction: 0.0006804662407375872\n",
      "iteration: 380, decoding loss: 0.005144036374986172, distance cost: 0.00016164952830877155, order reduction: 0.0005316578317433596\n",
      "iteration: 381, decoding loss: 0.004488540813326836, distance cost: 0.00017037653014995158, order reduction: 0.00047491106670349836\n",
      "iteration: 384, decoding loss: 0.0041848449036479, distance cost: 0.0002592332020867616, order reduction: 0.00044929422438144684\n",
      "iteration: 388, decoding loss: 0.004264527000486851, distance cost: 0.0001302973978454247, order reduction: 0.00039281047065742314\n",
      "iteration: 389, decoding loss: 0.004118895623832941, distance cost: 0.00012595714360941201, order reduction: 0.00043648516293615103\n",
      "iteration: 390, decoding loss: 0.0036464338190853596, distance cost: 0.00011914134665858, order reduction: 0.00030471780337393284\n",
      "iteration: 392, decoding loss: 0.003375193802639842, distance cost: 0.0001086569027393125, order reduction: 0.00028722433489747345\n",
      "iteration: 393, decoding loss: 0.0030156427528709173, distance cost: 0.00014035833009984344, order reduction: 0.000360965816071257\n",
      "iteration: 396, decoding loss: 0.003117248183116317, distance cost: 0.00010452159040141851, order reduction: 0.0002509532496333122\n",
      "iteration: 397, decoding loss: 0.003006939310580492, distance cost: 9.706008131615818e-05, order reduction: 0.00031452454277314246\n",
      "iteration: 399, decoding loss: 0.00245053693652153, distance cost: 7.787496724631637e-05, order reduction: 0.00016097429033834487\n",
      "iteration: 401, decoding loss: 0.0021046381443738937, distance cost: 9.255409531760961e-05, order reduction: 0.00022472759883385152\n",
      "iteration: 412, decoding loss: 0.0020524049177765846, distance cost: 8.157621778082103e-05, order reduction: 0.00016975615289993584\n",
      "iteration: 415, decoding loss: 0.0018891559448093176, distance cost: 7.411529804812744e-05, order reduction: 0.00016145176778081805\n",
      "iteration: 416, decoding loss: 0.0018557258881628513, distance cost: 6.622311775572598e-05, order reduction: 0.00016441363550256938\n",
      "iteration: 420, decoding loss: 0.0018444167217239738, distance cost: 7.32930566300638e-05, order reduction: 0.00015971825632732362\n",
      "iteration: 423, decoding loss: 0.0017713106935843825, distance cost: 6.333252531476319e-05, order reduction: 0.00013520426000468433\n",
      "iteration: 424, decoding loss: 0.001694039674475789, distance cost: 5.78125000174623e-05, order reduction: 0.0001180685794679448\n",
      "iteration: 425, decoding loss: 0.0016654850915074348, distance cost: 5.466399306897074e-05, order reduction: 0.00011268170783296227\n",
      "iteration: 426, decoding loss: 0.0016204823041334748, distance cost: 5.904837962589227e-05, order reduction: 0.00013507110998034477\n",
      "iteration: 427, decoding loss: 0.001642443472519517, distance cost: 4.415236981003545e-05, order reduction: 0.00011772844300139695\n",
      "iteration: 428, decoding loss: 0.001549780834466219, distance cost: 4.3560954509302974e-05, order reduction: 0.00011115897359559312\n",
      "iteration: 430, decoding loss: 0.0013206402072682977, distance cost: 6.258846406126395e-05, order reduction: 0.00011148184421472251\n",
      "iteration: 432, decoding loss: 0.0013489082921296358, distance cost: 4.5205750211607665e-05, order reduction: 9.637559560360387e-05\n",
      "iteration: 437, decoding loss: 0.0012381148990243673, distance cost: 6.371304334606975e-05, order reduction: 8.537200483260676e-05\n",
      "iteration: 442, decoding loss: 0.001209697569720447, distance cost: 3.838961129076779e-05, order reduction: 0.00011078826355515048\n",
      "iteration: 443, decoding loss: 0.0010779235744848847, distance cost: 4.133330367039889e-05, order reduction: 9.641257202019915e-05\n",
      "iteration: 445, decoding loss: 0.0010963574750348926, distance cost: 4.112411625101231e-05, order reduction: 7.402440678561106e-05\n",
      "iteration: 448, decoding loss: 0.0010840018512681127, distance cost: 3.228506466257386e-05, order reduction: 9.055415284819901e-05\n",
      "iteration: 452, decoding loss: 0.001042017131112516, distance cost: 4.4037031329935417e-05, order reduction: 7.370636012637988e-05\n",
      "iteration: 456, decoding loss: 0.0009638064075261354, distance cost: 2.6252595489495434e-05, order reduction: 6.909459625603631e-05\n",
      "iteration: 461, decoding loss: 0.0009194854646921158, distance cost: 5.15075953444466e-05, order reduction: 7.166864088503644e-05\n",
      "iteration: 464, decoding loss: 0.0009102064650505781, distance cost: 2.7502605007612146e-05, order reduction: 6.935316923772916e-05\n",
      "iteration: 465, decoding loss: 0.000823020760435611, distance cost: 2.1720825316151604e-05, order reduction: 3.908325015800074e-05\n",
      "iteration: 474, decoding loss: 0.0007639220566488802, distance cost: 2.3460519514628686e-05, order reduction: 4.917685510008596e-05\n",
      "iteration: 477, decoding loss: 0.0006793990032747388, distance cost: 2.704745202208869e-05, order reduction: 5.910805339226499e-05\n",
      "iteration: 485, decoding loss: 0.0006900417502038181, distance cost: 2.255883919133339e-05, order reduction: 4.5375934860203415e-05\n",
      "iteration: 486, decoding loss: 0.0005808032001368701, distance cost: 2.077405952150002e-05, order reduction: 4.968121720594354e-05\n",
      "iteration: 493, decoding loss: 0.0005486463196575642, distance cost: 2.16912230825983e-05, order reduction: 4.192808410152793e-05\n",
      "iteration: 500, decoding loss: 0.0005592594388872385, distance cost: 1.468538448534673e-05, order reduction: 3.557863237801939e-05\n",
      "iteration: 501, decoding loss: 0.0005570533103309572, distance cost: 1.5127596270758659e-05, order reduction: 3.605591700761579e-05\n",
      "iteration: 504, decoding loss: 0.0005294675356708467, distance cost: 2.0371031496324576e-05, order reduction: 3.910701707354747e-05\n",
      "iteration: 508, decoding loss: 0.0005097867106087506, distance cost: 1.8685181203181855e-05, order reduction: 4.344039552961476e-05\n",
      "iteration: 514, decoding loss: 0.0004942716914229095, distance cost: 2.072360075544566e-05, order reduction: 3.818405093625188e-05\n",
      "iteration: 518, decoding loss: 0.0004941917723044753, distance cost: 1.4133636796032079e-05, order reduction: 4.093639290658757e-05\n",
      "iteration: 521, decoding loss: 0.00048642727779224515, distance cost: 1.500195503467694e-05, order reduction: 4.027652903459966e-05\n",
      "iteration: 522, decoding loss: 0.00037081853952258825, distance cost: 1.4164716048981063e-05, order reduction: 3.209450369467959e-05\n",
      "iteration: 538, decoding loss: 0.000368011329555884, distance cost: 1.5046384760353249e-05, order reduction: 3.073030893574469e-05\n",
      "iteration: 549, decoding loss: 0.000335231568897143, distance cost: 1.1898362572537735e-05, order reduction: 3.7354056985350326e-05\n",
      "iteration: 551, decoding loss: 0.0003375252999830991, distance cost: 9.439154382562265e-06, order reduction: 2.3313648853218183e-05\n",
      "iteration: 554, decoding loss: 0.00031673061312176287, distance cost: 1.1355967217241414e-05, order reduction: 2.3186321413959377e-05\n",
      "iteration: 562, decoding loss: 0.00029367164825089276, distance cost: 1.1524830370035488e-05, order reduction: 2.829757249855902e-05\n",
      "iteration: 563, decoding loss: 0.00029660292784683406, distance cost: 1.060562499333173e-05, order reduction: 2.2496667952509597e-05\n",
      "iteration: 564, decoding loss: 0.00029506173450499773, distance cost: 9.653989764046855e-06, order reduction: 2.0075136490049772e-05\n",
      "iteration: 578, decoding loss: 0.0002839982626028359, distance cost: 8.32555815577507e-06, order reduction: 2.9141669074306265e-05\n",
      "iteration: 582, decoding loss: 0.00025190235464833677, distance cost: 1.047080604621442e-05, order reduction: 2.3354736185865477e-05\n",
      "iteration: 589, decoding loss: 0.00024168554227799177, distance cost: 6.259534075070405e-06, order reduction: 2.0038900402141735e-05\n",
      "iteration: 592, decoding loss: 0.0002341288491152227, distance cost: 7.47142439649906e-06, order reduction: 1.8670531062525697e-05\n",
      "iteration: 599, decoding loss: 0.00021447065228130668, distance cost: 9.348254025098868e-06, order reduction: 1.8910706785391085e-05\n",
      "iteration: 618, decoding loss: 0.00019952369621023536, distance cost: 8.663804692332633e-06, order reduction: 1.8984592315973714e-05\n",
      "iteration: 627, decoding loss: 0.00020667517674155533, distance cost: 6.039034815330524e-06, order reduction: 1.3928138287155889e-05\n",
      "iteration: 642, decoding loss: 0.0001677062246017158, distance cost: 5.036559741711244e-06, order reduction: 1.414848338754382e-05\n",
      "iteration: 653, decoding loss: 0.00016863275959622115, distance cost: 5.375268301577307e-06, order reduction: 1.0745282452262472e-05\n",
      "iteration: 660, decoding loss: 0.00015773078484926373, distance cost: 5.101747319713468e-06, order reduction: 1.6688372852513567e-05\n",
      "iteration: 672, decoding loss: 0.00015038580750115216, distance cost: 4.045088189741364e-06, order reduction: 1.2260825315024704e-05\n",
      "iteration: 676, decoding loss: 0.0001417288585798815, distance cost: 3.93657364838873e-06, order reduction: 1.374678686261177e-05\n",
      "iteration: 706, decoding loss: 0.00013159627269487828, distance cost: 4.5851384129491635e-06, order reduction: 1.1987427569692954e-05\n",
      "iteration: 713, decoding loss: 0.00012897574924863875, distance cost: 8.822455129120499e-06, order reduction: 9.151795893558301e-06\n",
      "iteration: 715, decoding loss: 0.00012716771743725985, distance cost: 4.051631094625918e-06, order reduction: 1.3014767318964005e-05\n",
      "iteration: 728, decoding loss: 0.0001170685573015362, distance cost: 2.873843641282292e-06, order reduction: 8.903553862182889e-06\n",
      "iteration: 752, decoding loss: 0.000114052789285779, distance cost: 4.39542782260105e-06, order reduction: 1.0365264643041883e-05\n",
      "iteration: 754, decoding loss: 0.00010905331873800606, distance cost: 3.649099880931317e-06, order reduction: 1.0260442650178447e-05\n",
      "iteration: 762, decoding loss: 0.00010708516492741182, distance cost: 3.1261292861017864e-06, order reduction: 6.8929307417420205e-06\n",
      "iteration: 771, decoding loss: 9.877726552076638e-05, distance cost: 2.5469028059887933e-06, order reduction: 7.745856237306725e-06\n",
      "iteration: 790, decoding loss: 9.724946721689776e-05, distance cost: 2.2136425741337007e-06, order reduction: 6.180241598485736e-06\n",
      "iteration: 809, decoding loss: 9.341206168755889e-05, distance cost: 2.6903785510512535e-06, order reduction: 8.94571167009417e-06\n",
      "iteration: 817, decoding loss: 9.08548609004356e-05, distance cost: 3.2866171295609092e-06, order reduction: 8.404867912759073e-06\n",
      "iteration: 820, decoding loss: 8.870384772308171e-05, distance cost: 2.4995067633426515e-06, order reduction: 6.683808351226617e-06\n",
      "[8.8703848e-05 2.4995068e-06 6.6838084e-06]\n"
     ]
    }
   ],
   "source": [
    "line_encoder, line_decoder, line_costs = decode_1d.train(line_points, 0, 1, device, n_training_iterations=1500,\n",
    "                                                          verbose=True, integration_resamples=30)\n",
    "print(line_costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39db9064-5bda-493c-a5a4-19fce6dfe504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0, decoding loss: 1.6550676822662354, distance cost: 0.49809741973876953, order reduction: 0.0016625752905383706\n",
      "iteration: 4, decoding loss: 1.2231171131134033, distance cost: 0.39548322558403015, order reduction: 0.0009572719573043287\n",
      "iteration: 6, decoding loss: 0.7209251523017883, distance cost: 0.25196513533592224, order reduction: 0.0010167787550017238\n",
      "iteration: 12, decoding loss: 0.4831049144268036, distance cost: 0.1685267984867096, order reduction: 0.003497066907584667\n",
      "iteration: 13, decoding loss: 0.2935255765914917, distance cost: 0.2268807590007782, order reduction: 0.0038263073656708\n",
      "iteration: 15, decoding loss: 0.28270217776298523, distance cost: 0.12442102283239365, order reduction: 0.00101851939689368\n",
      "iteration: 16, decoding loss: 0.16613347828388214, distance cost: 0.13647356629371643, order reduction: 0.00040018942672759295\n",
      "iteration: 17, decoding loss: 0.1647130250930786, distance cost: 0.12490878254175186, order reduction: 0.0002603985776659101\n",
      "iteration: 18, decoding loss: 0.1699191927909851, distance cost: 0.08120692521333694, order reduction: 0.0002574901154730469\n",
      "iteration: 21, decoding loss: 0.15099231898784637, distance cost: 0.06302929669618607, order reduction: 0.00024992311955429614\n",
      "iteration: 22, decoding loss: 0.14713068306446075, distance cost: 0.06072786822915077, order reduction: 0.0002393179020145908\n",
      "iteration: 23, decoding loss: 0.08588264882564545, distance cost: 0.05313066393136978, order reduction: 0.00017630842921789736\n",
      "iteration: 24, decoding loss: 0.082492396235466, distance cost: 0.044056765735149384, order reduction: 0.00019792864623013884\n",
      "iteration: 25, decoding loss: 0.040918052196502686, distance cost: 0.05077464133501053, order reduction: 0.00020183782908134162\n",
      "iteration: 27, decoding loss: 0.035377077758312225, distance cost: 0.03879348933696747, order reduction: 0.00017274680431000888\n",
      "iteration: 29, decoding loss: 0.05114065855741501, distance cost: 0.003750656498596072, order reduction: 0.000124767204397358\n",
      "iteration: 30, decoding loss: 0.04368912801146507, distance cost: 0.0018784571439027786, order reduction: 0.00010249564365949482\n",
      "iteration: 31, decoding loss: 0.03696543350815773, distance cost: 0.0007696357206441462, order reduction: 7.689042831771076e-05\n",
      "iteration: 34, decoding loss: 0.025332974269986153, distance cost: 0.004569257143884897, order reduction: 4.708665801445022e-05\n",
      "iteration: 35, decoding loss: 0.02109198085963726, distance cost: 0.005848584230989218, order reduction: 4.546483978629112e-05\n",
      "iteration: 36, decoding loss: 0.016871990635991096, distance cost: 0.009700226597487926, order reduction: 4.898135011899285e-05\n",
      "iteration: 37, decoding loss: 0.015689317137002945, distance cost: 0.005705700255930424, order reduction: 3.542954073054716e-05\n",
      "iteration: 40, decoding loss: 0.014285591430962086, distance cost: 0.0012159968027845025, order reduction: 1.656950371398125e-05\n",
      "iteration: 41, decoding loss: 0.010390526615083218, distance cost: 0.0013899453915655613, order reduction: 1.087521104636835e-05\n",
      "iteration: 43, decoding loss: 0.01127208024263382, distance cost: 0.00048604165203869343, order reduction: 5.674835847457871e-06\n",
      "iteration: 44, decoding loss: 0.007593676447868347, distance cost: 0.00037615906330756843, order reduction: 3.1963643323251745e-06\n",
      "iteration: 47, decoding loss: 0.00524256844073534, distance cost: 0.00022793507378082722, order reduction: 3.1157705961959437e-06\n",
      "iteration: 49, decoding loss: 0.004986297804862261, distance cost: 0.0003247885324526578, order reduction: 2.6618536139721982e-06\n",
      "iteration: 53, decoding loss: 0.0019888021051883698, distance cost: 0.00021025555906817317, order reduction: 4.061712104430626e-07\n",
      "iteration: 55, decoding loss: 0.0017820652574300766, distance cost: 0.000268942880211398, order reduction: 1.8930636542791035e-06\n",
      "iteration: 59, decoding loss: 0.001644954551011324, distance cost: 0.00012209638953208923, order reduction: 1.2280536338948878e-06\n",
      "iteration: 62, decoding loss: 0.0013456841697916389, distance cost: 7.036319584585726e-05, order reduction: 2.149883130186936e-06\n",
      "iteration: 64, decoding loss: 0.001069545978680253, distance cost: 0.00020922953262925148, order reduction: 8.200098022825841e-07\n",
      "iteration: 68, decoding loss: 0.0005573933594860137, distance cost: 7.932736480142921e-05, order reduction: 2.6655024498722923e-07\n",
      "iteration: 73, decoding loss: 0.0003038741706404835, distance cost: 0.00012731444439850748, order reduction: 1.2978977110833512e-06\n",
      "iteration: 75, decoding loss: 0.00024675106396898627, distance cost: 0.0001320736773777753, order reduction: 3.778088739636587e-07\n",
      "iteration: 76, decoding loss: 0.0001905891695059836, distance cost: 8.760755008552223e-05, order reduction: 1.0982685125782155e-06\n",
      "iteration: 83, decoding loss: 0.00018256947805639356, distance cost: 5.262965350993909e-05, order reduction: 3.744047774034698e-07\n",
      "iteration: 88, decoding loss: 0.00014261031174100935, distance cost: 4.617694139597006e-05, order reduction: 1.3078425808998873e-06\n",
      "iteration: 91, decoding loss: 0.00011557614925550297, distance cost: 6.0754697187803686e-05, order reduction: 3.4204649068669823e-07\n",
      "iteration: 93, decoding loss: 0.00010332982492400333, distance cost: 5.623483957606368e-05, order reduction: 2.410710521871806e-06\n",
      "iteration: 96, decoding loss: 5.056934242020361e-05, distance cost: 4.2777926864800975e-05, order reduction: 8.68127813191677e-07\n",
      "[5.0569342e-05 4.2777927e-05 8.6812781e-07]\n"
     ]
    }
   ],
   "source": [
    "ring_encoder, ring_decoder, ring_costs = decode_1d.train(line_points, 1, 0, device, n_training_iterations=1500,\n",
    "                                                          verbose=True, integration_resamples=30)\n",
    "print(ring_costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bb067d0-6e9d-4960-aade-03cdc7de22ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "    with torch.no_grad():\n",
    "        line_test_embedding = line_encoder(torch.tensor(np.expand_dims(line_phases, -1), dtype=torch.get_default_dtype()).to(device))\n",
    "        ring_test_embedding = ring_encoder(torch.tensor(np.expand_dims(line_phases, -1), dtype=torch.get_default_dtype()).to(device))\n",
    "\n",
    "    line_test_embedding = line_test_embedding.cpu().numpy()\n",
    "    ring_test_embedding = ring_test_embedding.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3646de8c-b537-409a-9944-ac6c75c6d366",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "axs.scatter(line_points[:, 0], line_points[:, 1])\n",
    "axs.plot(line_test_embedding[])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainconda",
   "language": "python",
   "name": "brainconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
