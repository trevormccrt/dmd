{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "sys.path.append(os.path.join(os.getenv(\"HOME\"), \"RNN_Manifold/\"))\n",
    "from manifold_encoder_decoder import s1_direct_product_generator, geometry_util, s1_direct_product_dimension_detecting_decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, generate some synthetic ring data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trevor/brainvenv/lib/python3.8/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0, decoding loss: 1.0021473169326782, distance cost: 0.007981647737324238\n",
      "iteration: 1, decoding loss: 0.6958116888999939, distance cost: 0.016865679994225502\n",
      "iteration: 2, decoding loss: 0.4463106393814087, distance cost: 0.02754906937479973\n",
      "iteration: 3, decoding loss: 0.36479389667510986, distance cost: 0.054413050413131714\n",
      "iteration: 4, decoding loss: 0.31404340267181396, distance cost: 0.0953064039349556\n",
      "iteration: 15, decoding loss: 0.31422102451324463, distance cost: 0.04604378715157509\n",
      "iteration: 16, decoding loss: 0.24714291095733643, distance cost: 0.039222944527864456\n",
      "iteration: 17, decoding loss: 0.20915479958057404, distance cost: 0.02600986883044243\n",
      "iteration: 18, decoding loss: 0.19301258027553558, distance cost: 0.021532151848077774\n",
      "iteration: 32, decoding loss: 0.15533214807510376, distance cost: 0.036485131829977036\n",
      "iteration: 33, decoding loss: 0.15926557779312134, distance cost: 0.030629189684987068\n",
      "iteration: 59, decoding loss: 0.16132749617099762, distance cost: 0.023391740396618843\n",
      "iteration: 60, decoding loss: 0.1541183590888977, distance cost: 0.02258181944489479\n",
      "iteration: 61, decoding loss: 0.13563621044158936, distance cost: 0.022688794881105423\n",
      "iteration: 62, decoding loss: 0.13115260004997253, distance cost: 0.02133065275847912\n",
      "iteration: 63, decoding loss: 0.12386979162693024, distance cost: 0.02268262580037117\n",
      "iteration: 64, decoding loss: 0.11587851494550705, distance cost: 0.021814240142703056\n",
      "iteration: 65, decoding loss: 0.09656908363103867, distance cost: 0.01882103830575943\n",
      "iteration: 67, decoding loss: 0.09135749936103821, distance cost: 0.020431483164429665\n",
      "iteration: 68, decoding loss: 0.08580174297094345, distance cost: 0.018118690699338913\n",
      "iteration: 69, decoding loss: 0.08370576053857803, distance cost: 0.018967404961586\n",
      "iteration: 70, decoding loss: 0.0777556374669075, distance cost: 0.020644377917051315\n",
      "iteration: 71, decoding loss: 0.07427682727575302, distance cost: 0.020122462883591652\n",
      "iteration: 72, decoding loss: 0.07174275815486908, distance cost: 0.01836116798222065\n",
      "iteration: 73, decoding loss: 0.0697636604309082, distance cost: 0.020264482125639915\n",
      "iteration: 74, decoding loss: 0.06890027225017548, distance cost: 0.020482586696743965\n",
      "iteration: 75, decoding loss: 0.06363692134618759, distance cost: 0.019315632060170174\n",
      "iteration: 159, decoding loss: 0.05043616145849228, distance cost: 0.03222130239009857\n",
      "iteration: 162, decoding loss: 0.05156644806265831, distance cost: 0.03044598549604416\n",
      "iteration: 163, decoding loss: 0.04854966327548027, distance cost: 0.03218020126223564\n",
      "iteration: 165, decoding loss: 0.05128038302063942, distance cost: 0.02622920647263527\n",
      "iteration: 166, decoding loss: 0.04708312451839447, distance cost: 0.027113361284136772\n",
      "iteration: 167, decoding loss: 0.048130303621292114, distance cost: 0.025837700814008713\n",
      "iteration: 169, decoding loss: 0.04748336970806122, distance cost: 0.026178864762187004\n",
      "iteration: 170, decoding loss: 0.046350087970495224, distance cost: 0.025382142513990402\n",
      "iteration: 171, decoding loss: 0.04799595847725868, distance cost: 0.02262136898934841\n",
      "iteration: 172, decoding loss: 0.0450102798640728, distance cost: 0.021706489846110344\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m encoder, decoder \u001B[38;5;241m=\u001B[39m \u001B[43ms1_direct_product_generator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m12\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_training_iterations\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3000\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m angles \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marange(start\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, stop\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m np\u001B[38;5;241m.\u001B[39mpi, step\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m)\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n",
      "File \u001B[0;32m~/RNN_Manifold/manifold_encoder_decoder/s1_direct_product_generator.py:29\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(manifold_dimension, embedding_dimension, device, encoder_hidden_dim, encoder_n_hidden, decoder_hidden_dim, decoder_n_hidden, integration_resamples, n_points_compare, batch_size, n_training_iterations, loss_stop_thresh)\u001B[0m\n\u001B[1;32m     26\u001B[0m re_encoded_points, _ \u001B[38;5;241m=\u001B[39m decoder_net(embedded_points)\n\u001B[1;32m     27\u001B[0m decoding_cost \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmean(torch\u001B[38;5;241m.\u001B[39msquare(re_encoded_points \u001B[38;5;241m-\u001B[39m sample_points))\n\u001B[0;32m---> 29\u001B[0m rolled_sample_phases \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mroll\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample_phases\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m angular_distances, model_distances \u001B[38;5;241m=\u001B[39m encoder_net\u001B[38;5;241m.\u001B[39mminimum_straight_line_distance(sample_phases, rolled_sample_phases, integration_resamples)\n\u001B[1;32m     31\u001B[0m normed_angular_distance \u001B[38;5;241m=\u001B[39m angular_distances \u001B[38;5;241m/\u001B[39m torch\u001B[38;5;241m.\u001B[39mmean(angular_distances)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "encoder, decoder = s1_direct_product_generator.train(1, 12, device, n_training_iterations=3000)\n",
    "angles = np.arange(start=0, stop=2 * np.pi, step=0.01)\n",
    "with torch.no_grad():\n",
    "    points = geometry_util.torch_angles_to_ring(torch.tensor(angles, dtype=torch.get_default_dtype()).to(device))\n",
    "    points = torch.unsqueeze(points, -2)\n",
    "    ring_embedded_points = encoder(points)\n",
    "ring_embedded_points = ring_embedded_points.cpu().numpy()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ring_embedded_points = ring_embedded_points/np.mean(np.abs(ring_embedded_points))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will detect the dimension of and decode the ring data we just generated. The below code looks for the best manifold of dimension max_n_dimensions or less and fits it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import importlib\n",
    "max_n_dimensions = 4\n",
    "importlib.reload(s1_direct_product_dimension_detecting_decoder)\n",
    "encoder, decoder, geometry_profile = s1_direct_product_dimension_detecting_decoder.train(ring_embedded_points, max_n_dimensions, device, decoder_weight=10, scrambling_weight=1, order_red_weight=1, n_training_iterations=15000)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The last return of this function, geometry_profile, contains the optimized value of scrambling_weights. If training worked, this should be close to 1 everywhere except for one index, which should be close to zero. This means the training process identified the fact that the underlying manifold had only one dimension. The index of the near-zero element, the \"primary dimension\" is the dimension we should use to address the 1D manifold."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "geometry_profile = geometry_profile.cpu().detach().numpy()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "used_dimension = np.argmin(geometry_profile)\n",
    "print(used_dimension)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If training worked, the encoder should not be sensitive to inputs except for the primary dimension. We can test this."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_batch_size = 100\n",
    "all_test_phases = np.random.uniform(-np.pi, np.pi, (test_batch_size, max_n_dimensions))\n",
    "all_test_phases[:, used_dimension] = np.ones(test_batch_size) * np.random.uniform(-np.pi, np.pi)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    test_embeddings = encoder(torch.tensor(geometry_util.angles_to_ring(all_test_phases), dtype=torch.get_default_dtype()).to(device)).cpu().numpy()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mean_result = np.mean(test_embeddings, axis=0)\n",
    "embedding_angle_shifts = np.arccos(np.einsum(\"j, ij -> i\", mean_result, test_embeddings)/(np.sqrt(mean_result.dot(mean_result) * np.einsum(\"ij, ij -> i\", test_embeddings, test_embeddings))))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(embedding_angle_shifts)\n",
    "ax.set_xlabel(\"Angular Dispalcement of Embedded Vector (rad)\")\n",
    "ax.set_ylabel(\"Counts\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that the embedding vector is only displaced slightly when completely random phases are supplied to the non-primary dimensions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also check that the returned decoder produces the right phases compared to ground truth values,"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    decoded_points, decoded_angles = decoder(torch.tensor(ring_embedded_points, dtype=torch.get_default_dtype()).to(device))\n",
    "\n",
    "predicted_phases = torch.squeeze(decoded_angles).cpu().numpy()[:, used_dimension]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def reference_phases(phases):\n",
    "    phases_refd = phases - phases[0]\n",
    "    phases_refd = np.arctan2(np.sin(phases_refd), np.cos(phases_refd))\n",
    "    return phases_refd * np.sign(phases_refd[int(len(phases)/4)])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compare_to_ground_truth(predicted_phases, ground_truth_phases, plot_ax):\n",
    "    refd_test_phases = reference_phases(predicted_phases)\n",
    "    refd_true_phases = reference_phases(ground_truth_phases)\n",
    "    line = np.arange(start=-np.pi, stop=np.pi, step=0.01)\n",
    "    plot_ax.scatter(refd_true_phases, refd_test_phases)\n",
    "    plot_ax.plot(line, line, color=\"black\", linestyle=\"--\", label=\"y=x\")\n",
    "    plot_ax.set_xlabel(\"True Phase\")\n",
    "    plot_ax.set_ylabel(\"Found Phase\")\n",
    "    return refd_test_phases, refd_true_phases\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "refd_predicted_phases, refd_true_phases = compare_to_ground_truth(predicted_phases, angles, ax)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
