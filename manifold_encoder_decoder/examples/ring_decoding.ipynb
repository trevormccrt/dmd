{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "First, let's embed a ring in 3D."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "from scipy import integrate\n",
    "import torch\n",
    "\n",
    "sys.path.append(os.path.join(os.getenv(\"HOME\"), \"RNN_Manifold/\"))\n",
    "from manifold_encoder_decoder import s1_direct_product_decoder, s1_direct_product_generator, geometry_util"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trevor/brainvenv/lib/python3.8/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0, decoding loss: 0.9843466877937317, distance cost: 0.013388672843575478\n",
      "iteration: 2, decoding loss: 0.5395281314849854, distance cost: 0.029766438528895378\n",
      "iteration: 3, decoding loss: 0.3357117474079132, distance cost: 0.0691237673163414\n",
      "iteration: 4, decoding loss: 0.2878531515598297, distance cost: 0.10309571772813797\n",
      "iteration: 44, decoding loss: 0.3322509825229645, distance cost: 0.03150106966495514\n",
      "iteration: 46, decoding loss: 0.30295056104660034, distance cost: 0.028324997052550316\n",
      "iteration: 47, decoding loss: 0.29810237884521484, distance cost: 0.028305288404226303\n",
      "iteration: 48, decoding loss: 0.2747058868408203, distance cost: 0.02693209983408451\n",
      "iteration: 50, decoding loss: 0.2715630829334259, distance cost: 0.0279324259608984\n",
      "iteration: 51, decoding loss: 0.2570587396621704, distance cost: 0.0338280089199543\n",
      "iteration: 52, decoding loss: 0.23910722136497498, distance cost: 0.028773006051778793\n",
      "iteration: 53, decoding loss: 0.22587983310222626, distance cost: 0.03742425888776779\n",
      "iteration: 54, decoding loss: 0.21444572508335114, distance cost: 0.03563966602087021\n",
      "iteration: 55, decoding loss: 0.20516915619373322, distance cost: 0.03971105441451073\n",
      "iteration: 56, decoding loss: 0.18856693804264069, distance cost: 0.04246358573436737\n",
      "iteration: 57, decoding loss: 0.17839676141738892, distance cost: 0.04567364230751991\n",
      "iteration: 58, decoding loss: 0.16572637856006622, distance cost: 0.050574518740177155\n",
      "iteration: 59, decoding loss: 0.14856673777103424, distance cost: 0.05210929363965988\n",
      "iteration: 60, decoding loss: 0.13365794718265533, distance cost: 0.0510331466794014\n",
      "iteration: 61, decoding loss: 0.1154414713382721, distance cost: 0.059920862317085266\n",
      "iteration: 62, decoding loss: 0.10156810283660889, distance cost: 0.06172597035765648\n",
      "iteration: 63, decoding loss: 0.08409867435693741, distance cost: 0.06699065864086151\n",
      "iteration: 64, decoding loss: 0.07719267904758453, distance cost: 0.06763772666454315\n",
      "iteration: 65, decoding loss: 0.06554979085922241, distance cost: 0.06814203411340714\n",
      "iteration: 67, decoding loss: 0.05913599953055382, distance cost: 0.07095947116613388\n",
      "iteration: 91, decoding loss: 0.08276335895061493, distance cost: 0.04652567580342293\n",
      "iteration: 92, decoding loss: 0.07708150148391724, distance cost: 0.04299665614962578\n",
      "iteration: 93, decoding loss: 0.07313979417085648, distance cost: 0.03998462110757828\n",
      "iteration: 94, decoding loss: 0.06393628567457199, distance cost: 0.040090374648571014\n",
      "iteration: 95, decoding loss: 0.06206901744008064, distance cost: 0.03611059859395027\n",
      "iteration: 96, decoding loss: 0.05526726692914963, distance cost: 0.031532589346170425\n",
      "iteration: 98, decoding loss: 0.05432538688182831, distance cost: 0.02717357687652111\n",
      "iteration: 101, decoding loss: 0.05381747707724571, distance cost: 0.022714897990226746\n",
      "iteration: 138, decoding loss: 0.04633603245019913, distance cost: 0.029165906831622124\n",
      "iteration: 141, decoding loss: 0.04076579213142395, distance cost: 0.03101588599383831\n",
      "iteration: 143, decoding loss: 0.039782069623470306, distance cost: 0.029225481674075127\n",
      "iteration: 146, decoding loss: 0.03332226723432541, distance cost: 0.033774033188819885\n",
      "iteration: 150, decoding loss: 0.031179280951619148, distance cost: 0.03530935198068619\n",
      "iteration: 158, decoding loss: 0.02837185002863407, distance cost: 0.038072001188993454\n",
      "iteration: 251, decoding loss: 0.04217865690588951, distance cost: 0.022760732099413872\n",
      "iteration: 255, decoding loss: 0.03916066884994507, distance cost: 0.023714108392596245\n",
      "iteration: 256, decoding loss: 0.03947561979293823, distance cost: 0.021754883229732513\n",
      "iteration: 257, decoding loss: 0.03599969670176506, distance cost: 0.023964887484908104\n",
      "iteration: 258, decoding loss: 0.03540473431348801, distance cost: 0.0229065902531147\n",
      "iteration: 260, decoding loss: 0.035095080733299255, distance cost: 0.022459371015429497\n",
      "iteration: 261, decoding loss: 0.03323919698596001, distance cost: 0.0210427138954401\n",
      "iteration: 263, decoding loss: 0.03135224059224129, distance cost: 0.022468285635113716\n",
      "iteration: 265, decoding loss: 0.031048286706209183, distance cost: 0.019207144156098366\n",
      "iteration: 267, decoding loss: 0.028565041720867157, distance cost: 0.01900619827210903\n",
      "iteration: 268, decoding loss: 0.028232548385858536, distance cost: 0.019179901108145714\n",
      "iteration: 269, decoding loss: 0.02876017987728119, distance cost: 0.015532576479017735\n",
      "iteration: 271, decoding loss: 0.025287693366408348, distance cost: 0.015802139416337013\n",
      "iteration: 272, decoding loss: 0.024576451629400253, distance cost: 0.015829166397452354\n",
      "iteration: 273, decoding loss: 0.025151992216706276, distance cost: 0.015090505592525005\n",
      "iteration: 275, decoding loss: 0.022860905155539513, distance cost: 0.015065089799463749\n",
      "iteration: 277, decoding loss: 0.021945951506495476, distance cost: 0.013940186239778996\n",
      "iteration: 278, decoding loss: 0.02025342360138893, distance cost: 0.013797800056636333\n",
      "iteration: 280, decoding loss: 0.02007942833006382, distance cost: 0.013034095987677574\n",
      "iteration: 282, decoding loss: 0.018109077587723732, distance cost: 0.012992634437978268\n",
      "iteration: 283, decoding loss: 0.016641419380903244, distance cost: 0.013038257136940956\n",
      "iteration: 284, decoding loss: 0.016086705029010773, distance cost: 0.011807380244135857\n",
      "iteration: 285, decoding loss: 0.015783188864588737, distance cost: 0.010620823130011559\n",
      "iteration: 287, decoding loss: 0.014846768230199814, distance cost: 0.010873486287891865\n",
      "iteration: 288, decoding loss: 0.01398712769150734, distance cost: 0.01065407320857048\n",
      "iteration: 289, decoding loss: 0.014857426285743713, distance cost: 0.009394516237080097\n",
      "iteration: 290, decoding loss: 0.013940734788775444, distance cost: 0.010127505287528038\n",
      "iteration: 291, decoding loss: 0.014269937761127949, distance cost: 0.009493941441178322\n",
      "iteration: 292, decoding loss: 0.013291564770042896, distance cost: 0.009159375913441181\n",
      "iteration: 293, decoding loss: 0.01234721764922142, distance cost: 0.008660544641315937\n",
      "iteration: 297, decoding loss: 0.012684603221714497, distance cost: 0.008058263920247555\n",
      "iteration: 298, decoding loss: 0.012809090316295624, distance cost: 0.00702751474454999\n",
      "iteration: 299, decoding loss: 0.01269212644547224, distance cost: 0.0066203586757183075\n",
      "iteration: 300, decoding loss: 0.012134983204305172, distance cost: 0.007011431269347668\n",
      "iteration: 302, decoding loss: 0.012316150590777397, distance cost: 0.006095024291425943\n",
      "iteration: 304, decoding loss: 0.012212349101901054, distance cost: 0.005998020991683006\n",
      "iteration: 305, decoding loss: 0.011909408494830132, distance cost: 0.005965293850749731\n",
      "iteration: 310, decoding loss: 0.01217495184391737, distance cost: 0.005425660405308008\n",
      "iteration: 314, decoding loss: 0.012542443349957466, distance cost: 0.005021098535507917\n",
      "iteration: 316, decoding loss: 0.011889627203345299, distance cost: 0.005506062880158424\n",
      "iteration: 406, decoding loss: 0.008397157303988934, distance cost: 0.00870446301996708\n",
      "iteration: 408, decoding loss: 0.00806773453950882, distance cost: 0.008653335273265839\n",
      "iteration: 410, decoding loss: 0.007903128862380981, distance cost: 0.008592743426561356\n",
      "iteration: 411, decoding loss: 0.0075565301813185215, distance cost: 0.008768925443291664\n",
      "iteration: 413, decoding loss: 0.0072648366913199425, distance cost: 0.008663509972393513\n",
      "iteration: 415, decoding loss: 0.006954082287847996, distance cost: 0.008808252401649952\n",
      "iteration: 418, decoding loss: 0.006697193253785372, distance cost: 0.008700842037796974\n",
      "iteration: 421, decoding loss: 0.0062864371575415134, distance cost: 0.009104708209633827\n",
      "iteration: 422, decoding loss: 0.006177268922328949, distance cost: 0.009122188203036785\n",
      "iteration: 423, decoding loss: 0.006293495651334524, distance cost: 0.008331275545060635\n",
      "iteration: 429, decoding loss: 0.005600192118436098, distance cost: 0.00851344782859087\n",
      "iteration: 437, decoding loss: 0.0054481541737914085, distance cost: 0.008604977279901505\n",
      "iteration: 441, decoding loss: 0.005007410887628794, distance cost: 0.008769691921770573\n",
      "iteration: 453, decoding loss: 0.005366490688174963, distance cost: 0.008331164717674255\n",
      "iteration: 540, decoding loss: 0.007838373072445393, distance cost: 0.005831744987517595\n",
      "iteration: 541, decoding loss: 0.008158856071531773, distance cost: 0.005472071003168821\n",
      "iteration: 543, decoding loss: 0.007884395308792591, distance cost: 0.005219064652919769\n",
      "iteration: 555, decoding loss: 0.007973316125571728, distance cost: 0.004716361407190561\n",
      "iteration: 565, decoding loss: 0.008444121107459068, distance cost: 0.004092538263648748\n",
      "iteration: 568, decoding loss: 0.008105284534394741, distance cost: 0.0039957440458238125\n",
      "iteration: 571, decoding loss: 0.008155119605362415, distance cost: 0.0033634507562965155\n",
      "iteration: 586, decoding loss: 0.007512692827731371, distance cost: 0.0033113386016339064\n",
      "iteration: 594, decoding loss: 0.007567155174911022, distance cost: 0.003034943714737892\n",
      "iteration: 604, decoding loss: 0.007450868375599384, distance cost: 0.002920927247032523\n",
      "iteration: 607, decoding loss: 0.007007615640759468, distance cost: 0.003256624098867178\n",
      "iteration: 609, decoding loss: 0.006920663174241781, distance cost: 0.00301798852160573\n",
      "iteration: 617, decoding loss: 0.007147545926272869, distance cost: 0.0027863318100571632\n",
      "iteration: 618, decoding loss: 0.006486282683908939, distance cost: 0.0028828212525695562\n",
      "iteration: 619, decoding loss: 0.006130637601017952, distance cost: 0.0032008301932364702\n",
      "iteration: 623, decoding loss: 0.005967685952782631, distance cost: 0.0032791311386972666\n",
      "iteration: 630, decoding loss: 0.006132515147328377, distance cost: 0.0029630777426064014\n",
      "iteration: 632, decoding loss: 0.006033682264387608, distance cost: 0.0030054885428398848\n",
      "iteration: 634, decoding loss: 0.005542302969843149, distance cost: 0.0033791977912187576\n",
      "iteration: 643, decoding loss: 0.006010939832776785, distance cost: 0.0028405524790287018\n",
      "iteration: 651, decoding loss: 0.005539055913686752, distance cost: 0.003222143743187189\n",
      "iteration: 654, decoding loss: 0.005390710197389126, distance cost: 0.0031599723733961582\n",
      "iteration: 657, decoding loss: 0.005182431545108557, distance cost: 0.0032672733068466187\n",
      "iteration: 661, decoding loss: 0.005215920507907867, distance cost: 0.003197611076757312\n",
      "iteration: 677, decoding loss: 0.004640581551939249, distance cost: 0.00371926068328321\n",
      "iteration: 678, decoding loss: 0.004610003903508186, distance cost: 0.0037018773145973682\n",
      "iteration: 679, decoding loss: 0.004535085521638393, distance cost: 0.003676998894661665\n",
      "iteration: 686, decoding loss: 0.00418667821213603, distance cost: 0.0038091547321528196\n",
      "iteration: 696, decoding loss: 0.004001772962510586, distance cost: 0.0039025703445076942\n",
      "iteration: 698, decoding loss: 0.003946036100387573, distance cost: 0.003675424959510565\n",
      "iteration: 714, decoding loss: 0.003854852868244052, distance cost: 0.003721751971170306\n",
      "iteration: 716, decoding loss: 0.0035833576694130898, distance cost: 0.0038977391086518764\n",
      "iteration: 739, decoding loss: 0.0034842637833207846, distance cost: 0.003917801193892956\n",
      "iteration: 741, decoding loss: 0.0033055192325264215, distance cost: 0.004000516142696142\n",
      "iteration: 752, decoding loss: 0.003204823937267065, distance cost: 0.0035243770107626915\n",
      "iteration: 771, decoding loss: 0.003184684319421649, distance cost: 0.0035116560757160187\n",
      "iteration: 778, decoding loss: 0.0030012393835932016, distance cost: 0.003318136790767312\n",
      "iteration: 787, decoding loss: 0.003195512806996703, distance cost: 0.003079387592151761\n",
      "iteration: 788, decoding loss: 0.002973623340949416, distance cost: 0.003071814775466919\n",
      "iteration: 791, decoding loss: 0.003002689452841878, distance cost: 0.0029675918631255627\n",
      "iteration: 793, decoding loss: 0.00285561615601182, distance cost: 0.003101987997069955\n",
      "iteration: 795, decoding loss: 0.00290099810808897, distance cost: 0.0030273012816905975\n",
      "iteration: 800, decoding loss: 0.0027524614706635475, distance cost: 0.002874137135222554\n",
      "iteration: 802, decoding loss: 0.002853517420589924, distance cost: 0.002698190277442336\n",
      "iteration: 809, decoding loss: 0.002794718835502863, distance cost: 0.00260537164285779\n",
      "iteration: 810, decoding loss: 0.0026254625990986824, distance cost: 0.0027137480210512877\n",
      "iteration: 811, decoding loss: 0.0026457805652171373, distance cost: 0.0024672544095665216\n",
      "iteration: 814, decoding loss: 0.0024479669518768787, distance cost: 0.0025797663256525993\n",
      "iteration: 818, decoding loss: 0.002345847198739648, distance cost: 0.0025707969907671213\n",
      "iteration: 823, decoding loss: 0.0025272935163229704, distance cost: 0.0023830444552004337\n",
      "iteration: 824, decoding loss: 0.002160985954105854, distance cost: 0.0026097327936440706\n",
      "iteration: 833, decoding loss: 0.002122166333720088, distance cost: 0.0024766160640865564\n",
      "iteration: 835, decoding loss: 0.0021432386711239815, distance cost: 0.0023618421982973814\n",
      "iteration: 839, decoding loss: 0.00205211597494781, distance cost: 0.002253911690786481\n",
      "iteration: 844, decoding loss: 0.0020060469396412373, distance cost: 0.0022075651213526726\n",
      "iteration: 848, decoding loss: 0.0019297483377158642, distance cost: 0.002029335591942072\n",
      "iteration: 852, decoding loss: 0.001982842106372118, distance cost: 0.001884232391603291\n",
      "iteration: 854, decoding loss: 0.0019263483118265867, distance cost: 0.0019204400014132261\n",
      "iteration: 869, decoding loss: 0.0016515107126906514, distance cost: 0.001984742470085621\n",
      "iteration: 873, decoding loss: 0.0017214231193065643, distance cost: 0.0018601015908643603\n",
      "iteration: 879, decoding loss: 0.0015218836488202214, distance cost: 0.001826507388614118\n",
      "iteration: 908, decoding loss: 0.0014255879214033484, distance cost: 0.001871722750365734\n",
      "iteration: 1157, decoding loss: 0.0012298760702833533, distance cost: 0.0020517054945230484\n",
      "iteration: 1164, decoding loss: 0.0012824664590880275, distance cost: 0.0019818039145320654\n",
      "iteration: 1167, decoding loss: 0.0011789952404797077, distance cost: 0.002037990605458617\n",
      "iteration: 1168, decoding loss: 0.0010982378153130412, distance cost: 0.0020162048749625683\n",
      "iteration: 1171, decoding loss: 0.0011585825122892857, distance cost: 0.0019428913947194815\n",
      "iteration: 1175, decoding loss: 0.0011567928595468402, distance cost: 0.001923712668940425\n",
      "iteration: 1176, decoding loss: 0.0011406159028410912, distance cost: 0.0019363132305443287\n",
      "iteration: 1178, decoding loss: 0.0011070768814533949, distance cost: 0.001863923273049295\n",
      "iteration: 1182, decoding loss: 0.0011549219489097595, distance cost: 0.0017924592830240726\n",
      "iteration: 1185, decoding loss: 0.0010761255398392677, distance cost: 0.0016909711994230747\n",
      "iteration: 1189, decoding loss: 0.0010031959973275661, distance cost: 0.001732613891363144\n",
      "iteration: 1194, decoding loss: 0.0010173447662964463, distance cost: 0.0016310822684317827\n",
      "iteration: 1200, decoding loss: 0.0010547696147114038, distance cost: 0.0015746020944789052\n",
      "iteration: 1203, decoding loss: 0.0008996964315883815, distance cost: 0.001580099924467504\n",
      "iteration: 1214, decoding loss: 0.0009412937797605991, distance cost: 0.0015274491161108017\n",
      "iteration: 1217, decoding loss: 0.0009110908140428364, distance cost: 0.001476641627959907\n",
      "iteration: 1221, decoding loss: 0.0008801974472589791, distance cost: 0.0014576151734218001\n",
      "iteration: 1230, decoding loss: 0.0008655554265715182, distance cost: 0.0014432426542043686\n",
      "iteration: 1233, decoding loss: 0.0009053360554389656, distance cost: 0.0013743280433118343\n",
      "iteration: 1235, decoding loss: 0.0008615166298113763, distance cost: 0.0012958489824086428\n",
      "iteration: 1245, decoding loss: 0.0008324371883645654, distance cost: 0.0012862476287409663\n",
      "iteration: 1251, decoding loss: 0.0008635981357656419, distance cost: 0.0011814737226814032\n",
      "iteration: 1259, decoding loss: 0.0008983196457847953, distance cost: 0.0011148193152621388\n",
      "iteration: 1268, decoding loss: 0.0007577399373985827, distance cost: 0.0011795557802543044\n",
      "iteration: 1271, decoding loss: 0.0007845648797228932, distance cost: 0.0011410816805437207\n",
      "iteration: 1284, decoding loss: 0.0007521362858824432, distance cost: 0.0011278451420366764\n",
      "iteration: 1520, decoding loss: 0.0009922970784828067, distance cost: 0.0008416996570304036\n",
      "iteration: 1533, decoding loss: 0.0009518262813799083, distance cost: 0.0008448712178505957\n",
      "iteration: 1534, decoding loss: 0.000978784286417067, distance cost: 0.0008099456899799407\n",
      "iteration: 1542, decoding loss: 0.0009258908103220165, distance cost: 0.0008045485010370612\n",
      "iteration: 1545, decoding loss: 0.000968863139860332, distance cost: 0.0007032183348201215\n",
      "iteration: 1552, decoding loss: 0.0008733835420571268, distance cost: 0.0007385265780612826\n",
      "iteration: 1561, decoding loss: 0.0008513284265063703, distance cost: 0.000689882377628237\n",
      "iteration: 1570, decoding loss: 0.0008647384820505977, distance cost: 0.0006345955189317465\n",
      "iteration: 1575, decoding loss: 0.0008066982845775783, distance cost: 0.000642906001303345\n",
      "iteration: 1581, decoding loss: 0.0007614599890075624, distance cost: 0.0006309178424999118\n",
      "iteration: 1584, decoding loss: 0.0007793079712428153, distance cost: 0.0006119107129052281\n",
      "iteration: 1588, decoding loss: 0.0007644551224075258, distance cost: 0.0006263009272515774\n",
      "iteration: 1589, decoding loss: 0.0007706271717324853, distance cost: 0.0006029132637195289\n",
      "iteration: 1592, decoding loss: 0.0007522589294239879, distance cost: 0.0006173175643198192\n",
      "iteration: 1594, decoding loss: 0.0007592387846671045, distance cost: 0.0005764588131569326\n",
      "iteration: 1595, decoding loss: 0.0006837610271759331, distance cost: 0.0006260191439650953\n",
      "iteration: 1602, decoding loss: 0.0006628741975873709, distance cost: 0.0005404949188232422\n",
      "iteration: 1605, decoding loss: 0.0006298521184362471, distance cost: 0.0005714063299819827\n",
      "iteration: 1613, decoding loss: 0.0006574640865437686, distance cost: 0.0004946407862007618\n",
      "iteration: 1623, decoding loss: 0.0006057952996343374, distance cost: 0.0004890752024948597\n",
      "iteration: 1637, decoding loss: 0.000609366805292666, distance cost: 0.00047690197243355215\n",
      "iteration: 1640, decoding loss: 0.0005511247436515987, distance cost: 0.0004409235261846334\n",
      "iteration: 1656, decoding loss: 0.000518625311087817, distance cost: 0.0004632802738342434\n",
      "iteration: 1659, decoding loss: 0.000536152336280793, distance cost: 0.00043695163913071156\n",
      "iteration: 1668, decoding loss: 0.000501719128806144, distance cost: 0.00045879819663241506\n",
      "iteration: 1685, decoding loss: 0.000467387173557654, distance cost: 0.00048638132284395397\n",
      "iteration: 1688, decoding loss: 0.000469879771117121, distance cost: 0.0004802773764822632\n",
      "iteration: 1691, decoding loss: 0.0004709342902060598, distance cost: 0.0004384854109957814\n",
      "iteration: 1720, decoding loss: 0.0004324453475419432, distance cost: 0.0004679449484683573\n",
      "iteration: 2136, decoding loss: 0.00037753547076135874, distance cost: 0.0005164567264728248\n",
      "iteration: 2146, decoding loss: 0.0003760752151720226, distance cost: 0.0004821809125132859\n",
      "iteration: 2150, decoding loss: 0.0003519569290801883, distance cost: 0.0004977157805114985\n",
      "iteration: 2158, decoding loss: 0.00035691220546141267, distance cost: 0.0004917370970360935\n",
      "iteration: 2164, decoding loss: 0.00035522092366591096, distance cost: 0.0004710053326562047\n",
      "iteration: 2167, decoding loss: 0.00034958039759658277, distance cost: 0.00047436406021006405\n",
      "iteration: 2171, decoding loss: 0.0003428354684729129, distance cost: 0.0004416834854055196\n",
      "iteration: 2193, decoding loss: 0.0003536980366334319, distance cost: 0.00042082014260813594\n",
      "iteration: 2197, decoding loss: 0.0003435558173805475, distance cost: 0.0004242919967509806\n",
      "iteration: 2204, decoding loss: 0.0003557822201400995, distance cost: 0.0003769534232560545\n",
      "iteration: 2218, decoding loss: 0.0003551308764144778, distance cost: 0.0003575182054191828\n",
      "iteration: 2227, decoding loss: 0.000354347430402413, distance cost: 0.0003448236675467342\n",
      "iteration: 2252, decoding loss: 0.0003658341884147376, distance cost: 0.0003088356170337647\n",
      "iteration: 2727, decoding loss: 0.0003219508798792958, distance cost: 0.0003082366019953042\n",
      "iteration: 2744, decoding loss: 0.0003229380236007273, distance cost: 0.00029107529553584754\n",
      "iteration: 2749, decoding loss: 0.0003176857717335224, distance cost: 0.0002955704985652119\n",
      "iteration: 2751, decoding loss: 0.00030127353966236115, distance cost: 0.00030772859463468194\n",
      "iteration: 2754, decoding loss: 0.00030172968399710953, distance cost: 0.00030669482657685876\n",
      "iteration: 2757, decoding loss: 0.00030078552663326263, distance cost: 0.00030581303872168064\n",
      "iteration: 2758, decoding loss: 0.00026946092839352787, distance cost: 0.0003002460871357471\n",
      "iteration: 2808, decoding loss: 0.0002504579024389386, distance cost: 0.0003183655207976699\n",
      "iteration: 2813, decoding loss: 0.00023942298139445484, distance cost: 0.00032431603176519275\n"
     ]
    }
   ],
   "source": [
    "encoder, decoder = s1_direct_product_generator.train(1, 3, device, n_training_iterations=3000)\n",
    "\n",
    "angles = np.arange(start=0, stop=2 * np.pi, step=0.01)\n",
    "with torch.no_grad():\n",
    "    points = geometry_util.torch_angles_to_ring(torch.tensor(angles, dtype=torch.get_default_dtype()).to(device))\n",
    "    points = torch.unsqueeze(points, -2)\n",
    "    test_embedding = encoder(points)\n",
    "test_embedding = test_embedding.cpu().numpy()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The shape it generates should be pretty much random, as there is nothing in the loss function we use that encourages a specific shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7f48cc1605e0>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib tk\n",
    "proj_fig = plt.figure()\n",
    "proj_axs = proj_fig.add_subplot(projection=\"3d\")\n",
    "proj_axs.scatter(test_embedding[:, 0], test_embedding[:, 1], test_embedding[:, 2], cmap=\"hsv\", c=angles)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's generate a higher dimensional ring"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0, decoding loss: 1.0117884874343872, distance cost: 0.002101421821862459\n",
      "iteration: 1, decoding loss: 0.49193379282951355, distance cost: 0.04621131345629692\n",
      "iteration: 2, decoding loss: 0.36218971014022827, distance cost: 0.06344244629144669\n",
      "iteration: 3, decoding loss: 0.3369177281856537, distance cost: 0.08562996238470078\n",
      "iteration: 5, decoding loss: 0.28197726607322693, distance cost: 0.12151344865560532\n",
      "iteration: 6, decoding loss: 0.2761057913303375, distance cost: 0.10752193629741669\n",
      "iteration: 7, decoding loss: 0.2822996973991394, distance cost: 0.09752345830202103\n",
      "iteration: 10, decoding loss: 0.32603174448013306, distance cost: 0.021332481876015663\n"
     ]
    }
   ],
   "source": [
    "encoder, decoder = s1_direct_product_generator.train(1, 24, device, n_training_iterations=3000)\n",
    "\n",
    "angles = np.arange(start=0, stop=2 * np.pi, step=0.01)\n",
    "with torch.no_grad():\n",
    "    points = geometry_util.torch_angles_to_ring(torch.tensor(angles, dtype=torch.get_default_dtype()).to(device))\n",
    "    points = torch.unsqueeze(points, -2)\n",
    "    high_d_generated_ring_data = encoder(points)\n",
    "high_d_generated_ring_data = high_d_generated_ring_data.cpu().numpy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And then decode it"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "high_d_generated_ring_data = high_d_generated_ring_data/np.mean(np.abs(high_d_generated_ring_data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder, decoder = s1_direct_product_decoder.train(data=high_d_generated_ring_data, manifold_dim=1, device=device,\n",
    "                                                   n_training_iterations=3000, decoder_weight=10, order_red_weight=0.1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    decoded_points, decoded_angles = decoder(torch.tensor(high_d_generated_ring_data, dtype=torch.get_default_dtype()).to(device))\n",
    "\n",
    "predicted_phases = torch.squeeze(decoded_angles).cpu().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def reference_phases(phases):\n",
    "    phases_refd = phases - phases[0]\n",
    "    phases_refd = np.arctan2(np.sin(phases_refd), np.cos(phases_refd))\n",
    "    return phases_refd * np.sign(phases_refd[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compare_to_ground_truth(predicted_phases, ground_truth_phases, plot_ax):\n",
    "    refd_test_phases = reference_phases(predicted_phases)\n",
    "    refd_true_phases = reference_phases(ground_truth_phases)\n",
    "    line = np.arange(start=-np.pi, stop=np.pi, step=0.01)\n",
    "    plot_ax.scatter(refd_true_phases, refd_test_phases)\n",
    "    plot_ax.plot(line, line, color=\"black\", linestyle=\"--\", label=\"y=x\")\n",
    "    plot_ax.set_xlabel(\"True Phase\")\n",
    "    plot_ax.set_ylabel(\"Found Phase\")\n",
    "    return refd_test_phases, refd_true_phases\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "refd_predicted_phases, refd_true_phases = compare_to_ground_truth(predicted_phases, angles, ax)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's do a harder problem. Let's decode noisy data generated by a dynamic system. First, the dynamics. We will use a typical ring attractor model,"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def conv_circ(signal, ker):\n",
    "    return np.fft.ifft(np.einsum(\"ij, j -> ij\", np.fft.fft(signal, axis=1), np.fft.fft(ker)), axis=1)\n",
    "\n",
    "\n",
    "def cosine_kernel(w_0, w_1, N):\n",
    "    step = 2/(N)\n",
    "    grid = np.arange(start=0, stop=2, step=step) * np.pi\n",
    "    weights = -w_0 + w_1 * np.cos(grid)\n",
    "    return weights\n",
    "\n",
    "\n",
    "def ring_attractor_dynamics(state, kernel, bias_vec, nonlin_fn):\n",
    "    if len(np.shape(state)) == 1:\n",
    "        state = np.expand_dims(state, -1)\n",
    "    state = np.transpose(state)\n",
    "    return np.transpose(-state + nonlin_fn(conv_circ(state, kernel) + bias_vec))\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return np.exp(x)/(np.exp(x) + 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate some samples of equalibrium states. We will generate around 50, to make things interesting."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N = 2 ** 7\n",
    "n_samples = 50\n",
    "\n",
    "init_conds = np.random.uniform(-1, 1, (n_samples, N)).astype(np.complex)\n",
    "\n",
    "w_0 = 1\n",
    "w_1 = 1\n",
    "kernel = cosine_kernel(w_0, w_1, N)\n",
    "\n",
    "\n",
    "def run_equilibriation(init_conds):\n",
    "    soln = integrate.solve_ivp(lambda _, y: ring_attractor_dynamics(y, kernel, np.zeros(N), sigmoid),\n",
    "                               [0, 20], init_conds, vectorized=True)\n",
    "    return soln.y[:, -1]\n",
    "\n",
    "\n",
    "p = mp.Pool()\n",
    "solns = np.array(p.map(run_equilibriation, init_conds))\n",
    "p.close()\n",
    "p.join()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add some noise"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ring_attractor_data = np.real(solns/np.mean(np.abs(solns)))\n",
    "noisy_ring_attractor_data = ring_attractor_data + np.random.normal(0, np.max(ring_attractor_data)/15, np.shape(ring_attractor_data))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note down the ground truth phases"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true_ring_att_phases = (np.argmax(ring_attractor_data, axis=1)/N) * 2 * np.pi"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(noisy_ring_attractor_data, aspect=\"auto\")\n",
    "ax.set_title(\"Raw activation data\")\n",
    "ax.set_xlabel(\"Neuron Index\")\n",
    "ax.set_ylabel(\"Datapoint\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now decode"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder, decoder = s1_direct_product_decoder.train(data=noisy_ring_attractor_data, manifold_dim=1, device=device,\n",
    "                                                   n_training_iterations=3000, decoder_weight=10, order_red_weight=0.1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    decoded_points, decoded_angles = decoder(torch.tensor(noisy_ring_attractor_data, dtype=torch.get_default_dtype()).to(device))\n",
    "\n",
    "ring_att_predicted_phases = torch.squeeze(decoded_angles).cpu().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots()\n",
    "refd_ring_att_predicted_phases, refd_ring_att_true_phases = compare_to_ground_truth(ring_att_predicted_phases, true_ring_att_phases, ax)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
